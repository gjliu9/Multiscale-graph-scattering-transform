{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import argparse\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from progress.bar import Bar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve,auc,accuracy_score\n",
    "import pickle\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import SGD\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "# import dgl.data.TUDataset as TUDataset\n",
    "# our package\n",
    "from Modules.STGST_torch_s2 import STGSTModule\n",
    "import Modules.graphScattering as np_GST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GST_coef_dataset(Dataset):\n",
    "#     def __init__(self, GSTcoe_all, label_all, split='train', test_rate=0.2):\n",
    "\n",
    "#         self.lenth = len(label_all)\n",
    "\n",
    "#         # if self.normalize:\n",
    "#         #     phis_mean = np.mean(phis[train_idx],axis=0)\n",
    "#         #     phis_std = np.std(phis[train_idx], axis=0)\n",
    "#         #     phis = (phis - phis_mean) / phis_std\n",
    "#         #     phis[np.isnan(phis)] = 0 # phis_std may be zero, remove invalid values here\n",
    "#         #     phis[np.isinf(phis)] = 0\n",
    "\n",
    "#         train_idx = int(self.lenth*(1-test_rate))\n",
    "\n",
    "#         if split == 'train':\n",
    "#             self.GSTcoe = GSTcoe_all[0:train_idx]\n",
    "#             self.labels = label_all[0:train_idx]\n",
    "#         elif split == 'test':\n",
    "#             self.GSTcoe = GSTcoe_all[(train_idx):]\n",
    "#             self.labels = label_all[(train_idx):]\n",
    "#         else:\n",
    "#             raise RuntimeError('Invalid split')\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.GSTcoe[index,:,:], self.labels[index]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "class GST_coef_dataset(Dataset):\n",
    "    def __init__(self, GSTcoe_all, label_all, split='train', test_rate=0.2):\n",
    "\n",
    "        self.lenth = len(label_all)\n",
    "\n",
    "        # if self.normalize:\n",
    "        #     phis_mean = np.mean(phis[train_idx],axis=0)\n",
    "        #     phis_std = np.std(phis[train_idx], axis=0)\n",
    "        #     phis = (phis - phis_mean) / phis_std\n",
    "        #     phis[np.isnan(phis)] = 0 # phis_std may be zero, remove invalid values here\n",
    "        #     phis[np.isinf(phis)] = 0\n",
    "\n",
    "        train_ls = []\n",
    "        test_ls = []\n",
    "        for i in range(self.lenth):\n",
    "            if i%int(1/test_rate)==0:\n",
    "                test_ls.append(i)\n",
    "            else:\n",
    "                train_ls.append(i)\n",
    "\n",
    "        # train_idx = int(self.lenth*(1-test_rate))\n",
    "\n",
    "\n",
    "        if split == 'train':\n",
    "            self.GSTcoe = GSTcoe_all[train_ls]\n",
    "            self.labels = label_all[train_ls]\n",
    "        elif split == 'test':\n",
    "            self.GSTcoe = GSTcoe_all[test_ls]\n",
    "            self.labels = label_all[test_ls]\n",
    "        else:\n",
    "            raise RuntimeError('Invalid split')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.GSTcoe[index,:,:], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)    \n",
    "    \n",
    "class MLPs(nn.Module):\n",
    "    def __init__(self, class_num=2, midnum = 128, nodeNum=None):\n",
    "        super(MLPs, self).__init__()\n",
    "        self.nodeNum = nodeNum\n",
    "        self.mlp1 = nn.Linear(in_features=self.nodeNum*63, out_features=midnum, bias=True)\n",
    "        # self.dropout1 = nn.Dropout(0.5)\n",
    "        self.mlp2 = nn.Linear(in_features=midnum, out_features=class_num, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.mlp2(x)\n",
    "        return x\n",
    "\n",
    "def computeNcoe(scale,layers):\n",
    "    num = 0\n",
    "    for i in range(layers):\n",
    "        num = num + pow(scale, i)\n",
    "    return num\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.layer = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "def sign(x):\n",
    "    x[x>=0] = 1\n",
    "    x[x<0] = -1\n",
    "    return x\n",
    "\n",
    "def loss_func(scores, label, type=\"svm\"):\n",
    "    assert type==\"perceptron\" or type==\"svm\" or type==\"CE\", \"loss type error\"\n",
    "    if type == \"perceptron\":\n",
    "        # 感知机损失函数，label取值集合为{-1, 1}\n",
    "        loss = -label*scores\n",
    "        loss[loss<=0] = 0\n",
    "    elif type == \"svm\":\n",
    "        # SVM损失函数，label取值集合为{-1, 1}\n",
    "        loss = 1-label*scores\n",
    "        loss[loss<=0] = 0\n",
    "    elif type == \"CE\":\n",
    "        loss = nn.CrossEntropyLoss(scores, label)\n",
    "           \n",
    "    \n",
    "    return torch.sum(loss)\n",
    "\n",
    "def pred(x):\n",
    "    return sign(x)\n",
    "\n",
    "def valid(test_loader,model):\n",
    "    pred_scores=[]\n",
    "    labels=[]\n",
    "    for j, (input, target) in enumerate(test_loader):\n",
    "        input_var = input.to(device).float()\n",
    "        target_var =target.to(device).int()\n",
    "        scores = model(input_var).squeeze(1).squeeze(1)\n",
    "        for m in range(len(target)):\n",
    "            pred_scores.append(scores[m].item())\n",
    "            labels.append(np.float(target[m].numpy()))\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    # print(labels)\n",
    "    labels[labels>0]=1\n",
    "    labels[labels<=0]=0    \n",
    "    # print(labels)\n",
    "    pred_scores=np.array(pred_scores)\n",
    "    # print(pred_scores)\n",
    "    pred_scores[pred_scores>0]=1\n",
    "    pred_scores[pred_scores<=0]=0\n",
    "    # print(pred_scores)\n",
    "    acc= accuracy_score(labels, pred_scores)\n",
    "    return acc\n",
    "\n",
    "def valid2(test_loader,model):\n",
    "    pred_scores=[]\n",
    "    labels=[]\n",
    "    for j, (input, target) in enumerate(test_loader):\n",
    "        input_var = input.to(device).float()\n",
    "        target_var =target.to(device).long()\n",
    "        scores = np.squeeze(model(input_var))\n",
    "#         print(scores)\n",
    "        for m in range(len(target)):\n",
    "#             print((scores[m].detach().cpu().numpy().tolist()).index(max(scores[m])))\n",
    "            pred_scores.append((scores[m].detach().cpu().numpy().tolist()).index(max(scores[m])))\n",
    "            labels.append(np.float(target[m].numpy()))\n",
    "#     print('label',labels)\n",
    "#     print('pred_scores',pred_scores)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    labels[labels>0]=1\n",
    "    labels[labels<=0]=0    \n",
    "\n",
    "    pred_scores=np.array(pred_scores)\n",
    "\n",
    "    acc= accuracy_score(labels, pred_scores)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "parser = argparse.ArgumentParser(description=\"GST configuration\")\n",
    "parser.add_argument(\"--datadir\", type=str, default='/DATA7_DB7/data/gjliu/dataset', help=\"path of dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='DD', help=\"name of dataset\")\n",
    "parser.add_argument(\"--split\", type=str, default='train')\n",
    "parser.add_argument(\"--epochs\", type=int, default= 10000)\n",
    "parser.add_argument(\"--batchsize\", type=int, default= 1, help=\"batch size of dataset\")\n",
    "parser.add_argument('--workers',default=1,type=int, metavar='N')\n",
    "parser.add_argument(\"--numScales\", type=int, default= 5, help=\"size of filter bank\")\n",
    "parser.add_argument(\"--numLayers\", type=int, default= 5, help=\"layers of GST\")\n",
    "args = parser.parse_known_args()[0]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "num_gst_coe = computeNcoe(args.numScales, args.numLayers)\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = dgl.data.TUDataset('ENZYMES')\n",
    "# data = dgl.data.GINDataset('DD', self_loop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 37)\n",
      "(1, 18, 37)\n",
      "(1, 18, 781)\n"
     ]
    }
   ],
   "source": [
    "g, label = data[0]\n",
    "A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "for i in range(g.num_edges()):\n",
    "    A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "\n",
    "GSTmodel = np_GST.DiffusionScattering(args.numScales, args.numLayers, A)     \n",
    "node_attr = np.transpose(g.ndata['node_attr'].numpy(),(1,0))\n",
    "print(np.shape(node_attr))\n",
    "node_attr = np.expand_dims(node_attr, axis=0)\n",
    "print(np.shape(node_attr))\n",
    "co_GST = GSTmodel.computeTransform(node_attr)\n",
    "print(np.shape(co_GST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 3\n",
      "Number of num_nodes: 45\n",
      "Number of num_edges: 3960\n",
      "ndata: {'_ID': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44])}\n",
      "edata: {'_ID': tensor([   0,    2,    4,  ..., 3954, 3956, 3958])}\n",
      "edges: (tensor([ 0,  0,  0,  ..., 44, 44, 44]), tensor([ 1,  2,  3,  ..., 41, 42, 43]))\n",
      "edges: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n",
      "edges: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
      "        11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "        29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,  0,  0,\n",
      "         2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
      "        38, 39, 40, 41, 42, 43, 44,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
      "        13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
      "        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,  0,  1,  0,  1,\n",
      "         3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21, 22])\n",
      "length 5000\n"
     ]
    }
   ],
   "source": [
    "g, label = data[0]\n",
    "print('Number of categories:', data.num_labels[0])\n",
    "print('Number of num_nodes:', g.num_nodes())\n",
    "print('Number of num_edges:', g.num_edges())\n",
    "print('ndata:', g.ndata)\n",
    "# print('ndata:', g.ndata['node_attr'])\n",
    "print('edata:', g.edata)\n",
    "print('edges:',g.edges())\n",
    "print('edges:',g.edges()[0][0:200])\n",
    "print('edges:',g.edges()[1][0:200])\n",
    "print('length',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00ebfc7b60c41cb9c91cd22fcdd9291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 18, 781)\n"
     ]
    }
   ],
   "source": [
    "# dataloader = GraphDataLoader(data, batch_size=1, shuffle=True)\n",
    "label_all = np.zeros(len(data))\n",
    "bar = Bar('>>>', fill='>', max=len(data))\n",
    "for k,(g, labels) in tqdm(enumerate(data)):\n",
    "\n",
    "    A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "    for i in range(g.num_edges()):\n",
    "        A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "\n",
    "    GSTmodel = np_GST.DiffusionScattering(args.numScales, args.numLayers, A)\n",
    "\n",
    "    node_attr = np.expand_dims(np.transpose(g.ndata['node_attr'].numpy(),(1,0)), axis=0)\n",
    "    # node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "    co_GST = GSTmodel.computeTransform(node_attr)\n",
    "    if k == 0:\n",
    "        num_coe = np.shape(co_GST)[2]\n",
    "        num_feature = np.shape(co_GST)[1]\n",
    "        GSTcoe_all = np.zeros((len(data),num_feature,num_coe))\n",
    "        print(np.shape(GSTcoe_all))\n",
    "    GSTcoe_all[k] = co_GST[0]\n",
    "    label_all[k] = int(labels.item())\n",
    "    bar.next()\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 18)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(g.ndata['node_attr'].numpy()[:,0:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSTdataset_train = GST_coef_dataset(GSTcoe_all, label_all, 'train')\n",
    "GSTdataset_test = GST_coef_dataset(GSTcoe_all, label_all, 'test')\n",
    "test_loader = torch.utils.data.DataLoader(GSTdataset_test, batch_size=args.batchsize,\n",
    "               shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([5.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([4.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([2.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n",
      "tensor([3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, (input, target) in enumerate(test_loader):\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 18)\n",
      "(600, 18, 1)\n",
      "(600, 18, 781)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DB/rhome/gjliu/.conda/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "phis_mean = np.mean(GSTcoe_all,axis=2)\n",
    "print(np.shape(phis_mean))\n",
    "phis_mean = np.expand_dims(phis_mean, axis=2)\n",
    "print(np.shape(phis_mean))\n",
    "phis_std = np.std(GSTcoe_all, axis=2)\n",
    "phis_std = np.expand_dims(phis_std, axis=2)\n",
    "GSTcoe_all = (GSTcoe_all - phis_mean)/phis_std\n",
    "print(np.shape(GSTcoe_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (78804581.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4560/78804581.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [0:100]\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([4,3,2,6,3,7,3])\n",
    "a[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPs(nn.Module):\n",
    "    def __init__(self, class_num=2, midnum = 128, nodeNum=None):\n",
    "        super(MLPs, self).__init__()\n",
    "        self.nodeNum = nodeNum\n",
    "        self.mlp1 = nn.Linear(in_features=self.nodeNum, out_features=midnum, bias=True)\n",
    "        # self.dropout1 = nn.Dropout(0.5)\n",
    "        self.mlp2 = nn.Linear(in_features=midnum, out_features=class_num, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.mlp2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(GSTcoe_all[0]) (1, 781)\n",
      "[[8.22222222e+00 2.27079080e+00 7.93636873e-01 7.64380080e-01\n",
      "  6.67090487e-01 3.84449919e-01 7.16750186e-01 2.77906196e-01\n",
      "  2.67350304e-01 2.45602695e-01 2.03523167e-01 2.79047787e-01\n",
      "  7.71773504e-02 6.95870825e-02 6.46447170e-02 5.55899136e-02\n",
      "  3.10825909e-01 9.06355558e-02 5.92137860e-02 5.09254776e-02\n",
      "  4.73949939e-02 2.38204682e-01 7.00564701e-02 4.28111443e-02\n",
      "  2.84209054e-02 1.84420264e-02 8.82163381e-02 4.02961963e-02\n",
      "  3.51149572e-02 2.45288696e-02 1.95637844e-02 2.87021262e-01\n",
      "  8.24744612e-02 7.31945365e-02 4.98342149e-02 3.24342970e-02\n",
      "  1.36340936e-01 2.97025268e-02 2.73919194e-02 2.20415321e-02\n",
      "  1.53706712e-02 8.93182020e-02 2.59239396e-02 2.27581883e-02\n",
      "  1.84113636e-02 1.46757966e-02 5.54591849e-02 2.40960491e-02\n",
      "  1.93493495e-02 1.30199606e-02 8.55968007e-03 3.40753147e-02\n",
      "  1.83193474e-02 1.79125772e-02 1.43881176e-02 1.18634534e-02\n",
      "  7.14946936e-02 3.45051481e-02 3.71366545e-02 3.40774451e-02\n",
      "  2.65244057e-02 3.91907177e-02 1.01631521e-02 8.84639090e-03\n",
      "  7.47928655e-03 4.75741451e-03 2.62915436e-02 7.43066040e-03\n",
      "  6.12455381e-03 4.34077813e-03 3.40841142e-03 1.28222074e-02\n",
      "  5.83598969e-03 4.67448605e-03 2.68477883e-03 2.10239035e-03\n",
      "  7.22371421e-03 3.76595295e-03 4.10835423e-03 3.64497708e-03\n",
      "  3.58759323e-03 8.88760080e-02 2.85231058e-02 2.80282737e-02\n",
      "  2.67768028e-02 2.64951670e-02 2.65688364e-02 8.47423557e-03\n",
      "  8.14499585e-03 6.76849800e-03 3.94755221e-03 1.96582868e-02\n",
      "  7.16487123e-03 6.67965103e-03 5.94293220e-03 4.66134748e-03\n",
      "  1.34991364e-02 5.87119348e-03 4.51332914e-03 3.17461838e-03\n",
      "  2.94211208e-03 5.89680237e-03 2.99255918e-03 2.70930346e-03\n",
      "  1.72079718e-03 1.97908490e-03 5.69317616e-02 1.86575510e-02\n",
      "  1.73629140e-02 1.33599167e-02 9.95618441e-03 2.17636949e-02\n",
      "  7.10164197e-03 6.60534331e-03 5.41433671e-03 3.28291729e-03\n",
      "  1.60621442e-02 5.27340633e-03 4.95087474e-03 4.60830353e-03\n",
      "  3.04690489e-03 9.05028815e-03 3.44779341e-03 3.29322048e-03\n",
      "  3.03688730e-03 2.14700116e-03 2.85879463e-03 1.89791415e-03\n",
      "  2.50492853e-03 2.67243558e-03 1.80978210e-03 2.68442953e-02\n",
      "  4.93366101e-03 3.54414567e-03 3.87693888e-03 4.61554257e-03\n",
      "  1.25676025e-02 2.64610963e-03 1.75264770e-03 1.31159541e-03\n",
      "  1.07011316e-03 1.08118627e-02 3.17870171e-03 2.17113303e-03\n",
      "  1.75225454e-03 1.45774515e-03 6.78160856e-03 2.79813556e-03\n",
      "  2.24027704e-03 1.89321695e-03 1.66866604e-03 2.76834399e-03\n",
      "  1.40674098e-03 1.42593890e-03 1.42950077e-03 1.35205801e-03\n",
      "  6.71826795e-02 2.93587571e-02 2.96822147e-02 2.26403119e-02\n",
      "  1.91734126e-02 2.96487525e-02 8.71907032e-03 6.93935930e-03\n",
      "  6.51043256e-03 6.40543872e-03 2.36564314e-02 7.48583851e-03\n",
      "  5.85482178e-03 4.77950868e-03 4.13763060e-03 1.31439150e-02\n",
      "  5.59443350e-03 5.14929677e-03 3.96158690e-03 3.62942414e-03\n",
      "  7.76721241e-03 3.63205191e-03 3.81656442e-03 3.55717956e-03\n",
      "  2.68566720e-03 2.59724657e-02 1.17400922e-02 1.23009643e-02\n",
      "  1.03517183e-02 7.06404134e-03 1.07145831e-02 3.83391116e-03\n",
      "  2.61012415e-03 2.19225937e-03 2.17693847e-03 7.89457703e-03\n",
      "  3.22772570e-03 2.62409063e-03 2.28894861e-03 2.18310062e-03\n",
      "  6.90145266e-03 2.88770984e-03 2.60718978e-03 2.35309277e-03\n",
      "  2.07577600e-03 3.77947966e-03 1.69906688e-03 1.60958094e-03\n",
      "  1.44919508e-03 1.09774921e-03 2.72305399e-02 9.69927736e-03\n",
      "  1.00171998e-02 9.95430284e-03 7.96613737e-03 7.93635286e-03\n",
      "  3.53878797e-03 3.41596160e-03 2.98706009e-03 2.29242727e-03\n",
      "  7.26729773e-03 3.05616967e-03 2.81970191e-03 2.19128435e-03\n",
      "  1.82350382e-03 5.85472583e-03 2.46291443e-03 2.08427662e-03\n",
      "  1.69801256e-03 1.43089726e-03 2.91676103e-03 1.23552749e-03\n",
      "  1.05226578e-03 8.94371509e-04 6.67769886e-04 1.50216474e-02\n",
      "  4.54438203e-03 4.04460762e-03 3.81320566e-03 3.51923193e-03\n",
      "  8.31705685e-03 1.98378375e-03 1.88543503e-03 1.79498245e-03\n",
      "  1.28540118e-03 7.07583030e-03 2.02870049e-03 2.06307874e-03\n",
      "  2.03422386e-03 1.64558229e-03 4.15982213e-03 1.37124326e-03\n",
      "  1.36226339e-03 1.31521013e-03 9.99910824e-04 1.24087733e-03\n",
      "  7.81593719e-04 9.69071580e-04 9.36813925e-04 5.81440386e-04\n",
      "  1.07045149e-02 2.90335316e-03 2.36684100e-03 1.77917128e-03\n",
      "  1.40533121e-03 6.49725184e-03 1.39602874e-03 8.45985672e-04\n",
      "  8.95389759e-04 1.02930815e-03 6.47695740e-03 1.54446430e-03\n",
      "  1.09134551e-03 1.19440029e-03 1.45293052e-03 3.45591690e-03\n",
      "  1.30025507e-03 1.30755831e-03 1.33104784e-03 1.35896046e-03\n",
      "  1.89964821e-03 1.15836590e-03 1.50071640e-03 1.49405565e-03\n",
      "  1.20709182e-03 2.62372949e-02 8.80748843e-03 7.91702821e-03\n",
      "  6.63446970e-03 4.36974419e-03 8.95421940e-03 3.16236537e-03\n",
      "  3.07139176e-03 2.81066549e-03 2.46425578e-03 7.84866734e-03\n",
      "  3.26130451e-03 2.76999199e-03 2.26049246e-03 2.47118769e-03\n",
      "  6.78953598e-03 3.02814494e-03 2.37713730e-03 1.39823018e-03\n",
      "  1.59392480e-03 3.96892929e-03 1.98272632e-03 1.87623617e-03\n",
      "  1.46929337e-03 1.42679617e-03 7.81755577e-03 3.56080009e-03\n",
      "  3.97937022e-03 4.18425674e-03 3.18833941e-03 4.30424120e-03\n",
      "  1.28154193e-03 8.11749561e-04 6.76922245e-04 6.17331462e-04\n",
      "  4.11537147e-03 1.27919647e-03 8.33694377e-04 5.63874568e-04\n",
      "  3.65559915e-04 2.71487606e-03 8.78752173e-04 5.97106557e-04\n",
      "  4.50797591e-04 4.01923904e-04 1.18753170e-03 5.43109831e-04\n",
      "  4.84510149e-04 3.52295762e-04 2.79985959e-04 5.74746434e-03\n",
      "  2.77576092e-03 2.98693837e-03 2.72839498e-03 2.12843934e-03\n",
      "  3.29736564e-03 8.91349074e-04 6.32660400e-04 6.20741892e-04\n",
      "  6.91567199e-04 2.34723083e-03 7.00438412e-04 5.23175760e-04\n",
      "  4.00899789e-04 2.58844753e-04 1.51612997e-03 5.46534941e-04\n",
      "  4.88435577e-04 4.07296083e-04 2.36529556e-04 5.22604832e-04\n",
      "  2.89337243e-04 3.30801167e-04 2.95077965e-04 2.28346666e-04\n",
      "  4.99090284e-03 1.33113358e-03 1.10482842e-03 7.23579109e-04\n",
      "  4.74998485e-04 2.27262001e-03 5.44470966e-04 3.62434854e-04\n",
      "  2.83902360e-04 2.67135302e-04 1.93235873e-03 5.10555129e-04\n",
      "  3.88044588e-04 3.30829992e-04 3.77034350e-04 8.93923412e-04\n",
      "  2.66366518e-04 2.56412150e-04 2.44308074e-04 2.12875130e-04\n",
      "  2.21217829e-04 1.52002463e-04 2.10180803e-04 2.31145544e-04\n",
      "  1.90897907e-04 3.06445395e-03 8.50190206e-04 6.65066088e-04\n",
      "  4.77233195e-04 5.73333915e-04 1.76409549e-03 3.95638848e-04\n",
      "  2.44022014e-04 2.45261540e-04 3.28006475e-04 1.47376043e-03\n",
      "  4.01182260e-04 3.34983265e-04 3.24023024e-04 3.81364838e-04\n",
      "  7.63170991e-04 3.91149458e-04 4.32428197e-04 4.23378722e-04\n",
      "  4.00882481e-04 5.00855418e-04 3.07846352e-04 4.08395615e-04\n",
      "  4.65351158e-04 4.22179307e-04 1.90737178e-02 6.09905284e-03\n",
      "  6.60435047e-03 6.08511373e-03 4.98434947e-03 8.50677593e-03\n",
      "  3.29449146e-03 2.50694985e-03 1.72153818e-03 1.72204242e-03\n",
      "  7.83487822e-03 2.60329969e-03 2.15468810e-03 1.34506494e-03\n",
      "  8.61865659e-04 5.13160199e-03 1.60933171e-03 1.35594952e-03\n",
      "  1.13871250e-03 1.30540491e-03 2.66541518e-03 1.20953119e-03\n",
      "  1.18404889e-03 1.51779121e-03 2.36520129e-03 6.02239323e-03\n",
      "  2.67790396e-03 2.54030370e-03 2.46202137e-03 2.32276142e-03\n",
      "  2.63721297e-03 9.11314237e-04 6.54023947e-04 5.13914952e-04\n",
      "  5.62251295e-04 2.48687851e-03 8.45005519e-04 5.93927698e-04\n",
      "  5.04929432e-04 5.48833872e-04 2.02129608e-03 7.19179336e-04\n",
      "  5.95794598e-04 5.14656796e-04 4.89358243e-04 7.03539708e-04\n",
      "  3.92777444e-04 4.68644092e-04 4.47617731e-04 2.86478449e-04\n",
      "  6.03435044e-03 2.44686705e-03 1.87786537e-03 1.17166777e-03\n",
      "  9.30677907e-04 2.47971887e-03 7.91840125e-04 6.23245286e-04\n",
      "  4.69508100e-04 3.48145508e-04 2.38642897e-03 8.48538090e-04\n",
      "  6.82508519e-04 4.88719190e-04 3.71460449e-04 1.39826169e-03\n",
      "  6.88079048e-04 6.70369756e-04 5.29428907e-04 4.31423391e-04\n",
      "  7.48973755e-04 4.83204639e-04 6.04922043e-04 5.67873008e-04\n",
      "  3.34049554e-04 4.92360205e-03 1.03053850e-03 8.47304275e-04\n",
      "  8.23450202e-04 9.55929275e-04 2.07056074e-03 5.10280187e-04\n",
      "  4.41851701e-04 4.31299907e-04 3.22432244e-04 1.51051012e-03\n",
      "  4.78276180e-04 4.81768352e-04 4.93781472e-04 3.75407097e-04\n",
      "  8.19610939e-04 2.98524841e-04 3.41673180e-04 3.43478376e-04\n",
      "  2.80683065e-04 3.72698109e-04 1.95457348e-04 2.46299572e-04\n",
      "  2.69386321e-04 2.95916312e-04 2.17632691e-03 6.26791936e-04\n",
      "  5.33691883e-04 3.85471135e-04 2.90671273e-04 1.26432719e-03\n",
      "  2.70202336e-04 1.89697653e-04 1.76037774e-04 1.21408950e-04\n",
      "  1.11763454e-03 2.60455518e-04 2.34461869e-04 1.99700156e-04\n",
      "  1.36468119e-04 4.40635468e-04 2.40040246e-04 2.52384802e-04\n",
      "  2.17380129e-04 2.09628866e-04 2.11127571e-04 1.35542212e-04\n",
      "  1.84845490e-04 2.34682850e-04 2.75826714e-04 1.79386735e-02\n",
      "  5.96639311e-03 3.60885382e-03 2.98641224e-03 3.87916184e-03\n",
      "  5.38200731e-03 1.49942488e-03 1.10764811e-03 1.08046417e-03\n",
      "  1.34860862e-03 4.29246741e-03 1.29206032e-03 9.92289077e-04\n",
      "  9.06687347e-04 1.17703223e-03 4.53993764e-03 1.64222066e-03\n",
      "  1.40101943e-03 1.00020450e-03 7.24802727e-04 2.02047721e-03\n",
      "  7.86179464e-04 8.24345287e-04 7.91602298e-04 6.81210659e-04\n",
      "  7.61573672e-03 2.31503018e-03 1.95434900e-03 1.92354239e-03\n",
      "  1.88615584e-03 2.31363366e-03 5.40297098e-04 4.34205535e-04\n",
      "  4.00201287e-04 3.86578708e-04 1.94912395e-03 6.20084171e-04\n",
      "  5.01770864e-04 4.28833932e-04 3.65085036e-04 1.47071003e-03\n",
      "  5.43209044e-04 5.31129017e-04 5.21028952e-04 4.25089333e-04\n",
      "  6.19200597e-04 3.75532600e-04 4.94709324e-04 5.21953977e-04\n",
      "  3.58857632e-04 3.27921443e-03 1.42315568e-03 1.53632827e-03\n",
      "  1.53057715e-03 9.55704241e-04 1.65104641e-03 6.20077041e-04\n",
      "  5.75431865e-04 5.27552604e-04 3.52996386e-04 1.85690886e-03\n",
      "  7.02156018e-04 5.20946126e-04 4.72291678e-04 3.92304805e-04\n",
      "  1.45851422e-03 5.39691757e-04 4.82607458e-04 4.70645968e-04\n",
      "  4.19139198e-04 7.29390135e-04 3.38596573e-04 3.91120872e-04\n",
      "  3.82940634e-04 3.03187210e-04 3.02085248e-03 1.02117402e-03\n",
      "  9.47096349e-04 8.55589086e-04 5.44357498e-04 1.20505620e-03\n",
      "  4.46322251e-04 4.74188504e-04 4.62726193e-04 3.09966512e-04\n",
      "  8.57355813e-04 3.96534384e-04 4.12374936e-04 3.96806197e-04\n",
      "  2.98449041e-04 7.88535921e-04 3.45204430e-04 3.74614074e-04\n",
      "  3.62587889e-04 2.62242634e-04 4.23630564e-04 2.47901842e-04\n",
      "  3.08226186e-04 3.27840653e-04 2.17621847e-04 8.16785257e-04\n",
      "  3.34344855e-04 3.67957281e-04 3.54025869e-04 2.46232734e-04\n",
      "  5.26773129e-04 2.11454294e-04 2.15098539e-04 2.23038834e-04\n",
      "  1.68016425e-04 7.70755096e-04 2.87033321e-04 2.77554080e-04\n",
      "  2.89564136e-04 2.23186600e-04 6.06897507e-04 2.64841739e-04\n",
      "  2.68540305e-04 2.84832182e-04 2.38196892e-04 3.11797658e-04\n",
      "  1.71521955e-04 1.95837238e-04 1.87471578e-04 1.15789777e-04\n",
      "  6.61769736e-03 2.78647965e-03 2.57817671e-03 2.18287947e-03\n",
      "  1.72589645e-03 2.28524794e-03 6.97909473e-04 4.64439950e-04\n",
      "  2.74157527e-04 2.13623283e-04 1.09521502e-03 3.97013151e-04\n",
      "  2.66496981e-04 1.50033314e-04 1.34964664e-04 6.19264047e-04\n",
      "  2.99091518e-04 2.75848496e-04 2.08020684e-04 1.67828302e-04\n",
      "  4.79379045e-04 2.59908395e-04 2.79620984e-04 2.74624903e-04\n",
      "  3.10988331e-04 2.15400328e-03 1.05863284e-03 1.08848634e-03\n",
      "  8.96319089e-04 5.49458489e-04 7.45462675e-04 2.33870679e-04\n",
      "  1.57863282e-04 1.24388302e-04 1.18618369e-04 6.47632517e-04\n",
      "  2.57227093e-04 1.99136940e-04 1.27552350e-04 9.45539278e-05\n",
      "  3.94120629e-04 1.84187729e-04 1.84653174e-04 1.42237212e-04\n",
      "  9.73902216e-05 1.64622839e-04 1.00920138e-04 1.27244117e-04\n",
      "  1.33273662e-04 1.24123207e-04 2.42272050e-03 1.12321605e-03\n",
      "  9.46732727e-04 6.93031746e-04 5.40822343e-04 7.79999450e-04\n",
      "  2.68740096e-04 2.28190371e-04 1.66265267e-04 1.24076836e-04\n",
      "  6.45336723e-04 2.71509981e-04 2.26375300e-04 1.61724701e-04\n",
      "  9.90813005e-05 4.06066999e-04 1.84634013e-04 1.64980030e-04\n",
      "  1.17539584e-04 6.35817375e-05 2.30458845e-04 1.27555956e-04\n",
      "  1.39894818e-04 1.22804456e-04 1.03197948e-04 1.70983189e-03\n",
      "  6.74748666e-04 5.63491835e-04 4.20836953e-04 3.40616927e-04\n",
      "  5.75927152e-04 2.25800352e-04 2.01007627e-04 1.60921155e-04\n",
      "  1.21386915e-04 6.05053760e-04 2.31512596e-04 1.88005694e-04\n",
      "  1.13984938e-04 6.52865508e-05 3.29901143e-04 1.30041233e-04\n",
      "  1.10661810e-04 9.15720593e-05 7.34074357e-05 2.27912267e-04\n",
      "  1.24960379e-04 1.38452588e-04 1.25238747e-04 1.07208372e-04\n",
      "  6.86912079e-04 3.08105960e-04 2.97608712e-04 2.67959997e-04\n",
      "  2.18157183e-04 4.01544355e-04 1.53773395e-04 1.25847361e-04\n",
      "  9.75006779e-05 7.78887359e-05 4.36177601e-04 1.80427891e-04\n",
      "  1.47750812e-04 1.04459708e-04 6.33759820e-05 3.04257115e-04\n",
      "  1.57430566e-04 1.65561704e-04 1.32616609e-04 7.73197008e-05\n",
      "  2.11409109e-04 1.17178428e-04 1.31396100e-04 1.15615987e-04\n",
      "  8.05827433e-05]]\n"
     ]
    }
   ],
   "source": [
    "print('np.shape(GSTcoe_all[0])',np.shape(GSTcoe_all[0]))\n",
    "print(GSTcoe_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9248)\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "label3 = torch.LongTensor([9, 2, 5])\n",
    "logits3 = torch.randn(3, 10)\n",
    "loss_f3 = nn.CrossEntropyLoss()\n",
    "print(loss_f3(logits3, label3))\n",
    "print(np.shape(label3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, (input, target) in (enumerate(test_loader)):\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9999\n",
      "----------\n",
      "loss= 0.6817166456459883 acc= 0.5964125560538116 acctrain= 0.5955056179775281\n",
      "epoch time: 1.542403221130371   total time: 1.542661428451538\n",
      "Epoch 1/9999\n",
      "----------\n",
      "epoch time: 1.0620448589324951   total time: 2.604768991470337\n",
      "Epoch 2/9999\n",
      "----------\n",
      "epoch time: 0.9509048461914062   total time: 3.5563743114471436\n",
      "Epoch 3/9999\n",
      "----------\n",
      "epoch time: 1.0759968757629395   total time: 4.632553577423096\n",
      "Epoch 4/9999\n",
      "----------\n",
      "epoch time: 1.0673606395721436   total time: 5.700119495391846\n",
      "Epoch 5/9999\n",
      "----------\n",
      "epoch time: 1.0860064029693604   total time: 6.786685466766357\n",
      "Epoch 6/9999\n",
      "----------\n",
      "epoch time: 1.0278024673461914   total time: 7.814768552780151\n",
      "Epoch 7/9999\n",
      "----------\n",
      "epoch time: 1.091982126235962   total time: 8.9070565700531\n",
      "Epoch 8/9999\n",
      "----------\n",
      "epoch time: 0.9970815181732178   total time: 9.904402732849121\n",
      "Epoch 9/9999\n",
      "----------\n",
      "epoch time: 1.038583517074585   total time: 10.943108558654785\n",
      "Epoch 10/9999\n",
      "----------\n",
      "loss= 0.6458661377162677 acc= 0.6636771300448431 acctrain= 0.6303370786516854\n",
      "epoch time: 1.8496203422546387   total time: 12.79295825958252\n",
      "Epoch 11/9999\n",
      "----------\n",
      "epoch time: 1.4613845348358154   total time: 14.25445008277893\n",
      "Epoch 12/9999\n",
      "----------\n",
      "epoch time: 1.5987389087677002   total time: 15.853373050689697\n",
      "Epoch 13/9999\n",
      "----------\n",
      "epoch time: 1.6544160842895508   total time: 17.50795006752014\n",
      "Epoch 14/9999\n",
      "----------\n",
      "epoch time: 1.6837515830993652   total time: 19.192501544952393\n",
      "Epoch 15/9999\n",
      "----------\n",
      "epoch time: 1.6127402782440186   total time: 20.805490493774414\n",
      "Epoch 16/9999\n",
      "----------\n",
      "epoch time: 1.0803213119506836   total time: 21.886045455932617\n",
      "Epoch 17/9999\n",
      "----------\n",
      "epoch time: 0.5039875507354736   total time: 22.390966176986694\n",
      "Epoch 18/9999\n",
      "----------\n",
      "epoch time: 0.48118114471435547   total time: 22.87233805656433\n",
      "Epoch 19/9999\n",
      "----------\n",
      "epoch time: 0.46293067932128906   total time: 23.33540368080139\n",
      "Epoch 20/9999\n",
      "----------\n",
      "loss= 0.6332123862253711 acc= 0.6322869955156951 acctrain= 0.6325842696629214\n",
      "epoch time: 0.6982746124267578   total time: 24.033791542053223\n",
      "Epoch 21/9999\n",
      "----------\n",
      "epoch time: 0.5039002895355225   total time: 24.53859829902649\n",
      "Epoch 22/9999\n",
      "----------\n",
      "epoch time: 0.4805583953857422   total time: 25.019868850708008\n",
      "Epoch 23/9999\n",
      "----------\n",
      "epoch time: 0.5203616619110107   total time: 25.540353536605835\n",
      "Epoch 24/9999\n",
      "----------\n",
      "epoch time: 0.5688536167144775   total time: 26.109458208084106\n",
      "Epoch 25/9999\n",
      "----------\n",
      "epoch time: 0.5028173923492432   total time: 26.612607717514038\n",
      "Epoch 26/9999\n",
      "----------\n",
      "epoch time: 0.4858121871948242   total time: 27.098530054092407\n",
      "Epoch 27/9999\n",
      "----------\n",
      "epoch time: 0.47161006927490234   total time: 27.570306301116943\n",
      "Epoch 28/9999\n",
      "----------\n",
      "epoch time: 0.5493028163909912   total time: 28.119729042053223\n",
      "Epoch 29/9999\n",
      "----------\n",
      "epoch time: 0.49962854385375977   total time: 28.619603157043457\n",
      "Epoch 30/9999\n",
      "----------\n",
      "loss= 0.6192678642112578 acc= 0.7040358744394619 acctrain= 0.6775280898876405\n",
      "epoch time: 0.7122440338134766   total time: 29.33237338066101\n",
      "Epoch 31/9999\n",
      "----------\n",
      "epoch time: 0.562614917755127   total time: 29.895262718200684\n",
      "Epoch 32/9999\n",
      "----------\n",
      "epoch time: 0.5163068771362305   total time: 30.41174817085266\n",
      "Epoch 33/9999\n",
      "----------\n",
      "epoch time: 0.9009289741516113   total time: 31.31292486190796\n",
      "Epoch 34/9999\n",
      "----------\n",
      "epoch time: 1.4588379859924316   total time: 32.77196645736694\n",
      "Epoch 35/9999\n",
      "----------\n",
      "epoch time: 1.58787202835083   total time: 34.360766649246216\n",
      "Epoch 36/9999\n",
      "----------\n",
      "epoch time: 1.52951979637146   total time: 35.89184045791626\n",
      "Epoch 37/9999\n",
      "----------\n",
      "epoch time: 1.4174473285675049   total time: 37.310107707977295\n",
      "Epoch 38/9999\n",
      "----------\n",
      "epoch time: 1.3229029178619385   total time: 38.633596420288086\n",
      "Epoch 39/9999\n",
      "----------\n",
      "epoch time: 1.492844820022583   total time: 40.12667679786682\n",
      "Epoch 40/9999\n",
      "----------\n",
      "loss= 0.619141975726782 acc= 0.7040358744394619 acctrain= 0.6730337078651686\n",
      "epoch time: 2.4297454357147217   total time: 42.55867910385132\n",
      "Epoch 41/9999\n",
      "----------\n",
      "epoch time: 1.3089590072631836   total time: 43.86822819709778\n",
      "Epoch 42/9999\n",
      "----------\n",
      "epoch time: 1.466552972793579   total time: 45.334933042526245\n",
      "Epoch 43/9999\n",
      "----------\n",
      "epoch time: 1.5772268772125244   total time: 46.91250729560852\n",
      "Epoch 44/9999\n",
      "----------\n",
      "epoch time: 1.431518316268921   total time: 48.344297885894775\n",
      "Epoch 45/9999\n",
      "----------\n",
      "epoch time: 1.4001681804656982   total time: 49.745519399642944\n",
      "Epoch 46/9999\n",
      "----------\n",
      "epoch time: 1.4746425151824951   total time: 51.220295667648315\n",
      "Epoch 47/9999\n",
      "----------\n",
      "epoch time: 1.8752219676971436   total time: 53.09573411941528\n",
      "Epoch 48/9999\n",
      "----------\n",
      "epoch time: 1.7512986660003662   total time: 54.84718179702759\n",
      "Epoch 49/9999\n",
      "----------\n",
      "epoch time: 1.775510549545288   total time: 56.62390470504761\n",
      "Epoch 50/9999\n",
      "----------\n",
      "loss= 0.6116785703753143 acc= 0.6771300448430493 acctrain= 0.6561797752808989\n",
      "epoch time: 2.871997833251953   total time: 59.49614930152893\n",
      "Epoch 51/9999\n",
      "----------\n",
      "epoch time: 1.4182257652282715   total time: 60.915019512176514\n",
      "Epoch 52/9999\n",
      "----------\n",
      "epoch time: 1.4298796653747559   total time: 62.34535574913025\n",
      "Epoch 53/9999\n",
      "----------\n",
      "epoch time: 1.4882996082305908   total time: 63.833858251571655\n",
      "Epoch 54/9999\n",
      "----------\n",
      "epoch time: 1.5952587127685547   total time: 65.43121552467346\n",
      "Epoch 55/9999\n",
      "----------\n",
      "epoch time: 1.364375352859497   total time: 66.79589509963989\n",
      "Epoch 56/9999\n",
      "----------\n",
      "epoch time: 1.3969855308532715   total time: 68.19406175613403\n",
      "Epoch 57/9999\n",
      "----------\n",
      "epoch time: 1.4075336456298828   total time: 69.60181951522827\n",
      "Epoch 58/9999\n",
      "----------\n",
      "epoch time: 0.7252261638641357   total time: 70.32866597175598\n",
      "Epoch 59/9999\n",
      "----------\n",
      "epoch time: 0.4868588447570801   total time: 70.81565165519714\n",
      "Epoch 60/9999\n",
      "----------\n",
      "loss= 0.612419178199875 acc= 0.726457399103139 acctrain= 0.6921348314606741\n",
      "epoch time: 0.7751104831695557   total time: 71.59087467193604\n",
      "Epoch 61/9999\n",
      "----------\n",
      "epoch time: 0.48659563064575195   total time: 72.07838797569275\n",
      "Epoch 62/9999\n",
      "----------\n",
      "epoch time: 0.44840168952941895   total time: 72.52691721916199\n",
      "Epoch 63/9999\n",
      "----------\n",
      "epoch time: 0.465595006942749   total time: 72.99262261390686\n",
      "Epoch 64/9999\n",
      "----------\n",
      "epoch time: 0.4673151969909668   total time: 73.46004986763\n",
      "Epoch 65/9999\n",
      "----------\n",
      "epoch time: 0.4631619453430176   total time: 73.92333364486694\n",
      "Epoch 66/9999\n",
      "----------\n",
      "epoch time: 0.5120189189910889   total time: 74.43548440933228\n",
      "Epoch 67/9999\n",
      "----------\n",
      "epoch time: 0.5466012954711914   total time: 74.98248863220215\n",
      "Epoch 68/9999\n",
      "----------\n",
      "epoch time: 0.4704399108886719   total time: 75.45308351516724\n",
      "Epoch 69/9999\n",
      "----------\n",
      "epoch time: 0.5089101791381836   total time: 75.9621262550354\n",
      "Epoch 70/9999\n",
      "----------\n",
      "loss= 0.6076328803872848 acc= 0.7219730941704036 acctrain= 0.6797752808988764\n",
      "epoch time: 0.8347923755645752   total time: 76.7977237701416\n",
      "Epoch 71/9999\n",
      "----------\n",
      "epoch time: 1.0659489631652832   total time: 77.86395978927612\n",
      "Epoch 72/9999\n",
      "----------\n",
      "epoch time: 1.5155980587005615   total time: 79.38114500045776\n",
      "Epoch 73/9999\n",
      "----------\n",
      "epoch time: 1.5619823932647705   total time: 80.94338250160217\n",
      "Epoch 74/9999\n",
      "----------\n",
      "epoch time: 1.550067663192749   total time: 82.49446439743042\n",
      "Epoch 75/9999\n",
      "----------\n",
      "epoch time: 1.5546560287475586   total time: 84.04996633529663\n",
      "Epoch 76/9999\n",
      "----------\n",
      "epoch time: 1.4076805114746094   total time: 85.45791625976562\n",
      "Epoch 77/9999\n",
      "----------\n",
      "epoch time: 1.8964853286743164   total time: 87.35466027259827\n",
      "Epoch 78/9999\n",
      "----------\n",
      "epoch time: 1.854942798614502   total time: 89.20996379852295\n",
      "Epoch 79/9999\n",
      "----------\n",
      "epoch time: 1.5231797695159912   total time: 90.73455762863159\n",
      "Epoch 80/9999\n",
      "----------\n",
      "loss= 0.6011040197359607 acc= 0.7219730941704036 acctrain= 0.6876404494382022\n",
      "epoch time: 2.289971351623535   total time: 93.02488613128662\n",
      "Epoch 81/9999\n",
      "----------\n",
      "epoch time: 1.4228765964508057   total time: 94.4479033946991\n",
      "Epoch 82/9999\n",
      "----------\n",
      "epoch time: 1.5167438983917236   total time: 95.96497845649719\n",
      "Epoch 83/9999\n",
      "----------\n",
      "epoch time: 1.4263966083526611   total time: 97.39170384407043\n",
      "Epoch 84/9999\n",
      "----------\n",
      "epoch time: 1.8982000350952148   total time: 99.29022026062012\n",
      "Epoch 85/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time: 1.770918369293213   total time: 101.06136727333069\n",
      "Epoch 86/9999\n",
      "----------\n",
      "epoch time: 1.8035533428192139   total time: 102.86540532112122\n",
      "Epoch 87/9999\n",
      "----------\n",
      "epoch time: 1.6863203048706055   total time: 104.55197048187256\n",
      "Epoch 88/9999\n",
      "----------\n",
      "epoch time: 1.8194189071655273   total time: 106.3716812133789\n",
      "Epoch 89/9999\n",
      "----------\n",
      "epoch time: 1.2544794082641602   total time: 107.62737560272217\n",
      "Epoch 90/9999\n",
      "----------\n",
      "loss= 0.5976464157681829 acc= 0.695067264573991 acctrain= 0.6808988764044944\n",
      "epoch time: 2.4262635707855225   total time: 110.05464696884155\n",
      "Epoch 91/9999\n",
      "----------\n",
      "epoch time: 1.440401554107666   total time: 111.495774269104\n",
      "Epoch 92/9999\n",
      "----------\n",
      "epoch time: 1.5508835315704346   total time: 113.04700970649719\n",
      "Epoch 93/9999\n",
      "----------\n",
      "epoch time: 1.3359439373016357   total time: 114.38319134712219\n",
      "Epoch 94/9999\n",
      "----------\n",
      "epoch time: 1.3570327758789062   total time: 115.74044466018677\n",
      "Epoch 95/9999\n",
      "----------\n",
      "epoch time: 0.9402897357940674   total time: 116.68118524551392\n",
      "Epoch 96/9999\n",
      "----------\n",
      "epoch time: 0.5750370025634766   total time: 117.25645184516907\n",
      "Epoch 97/9999\n",
      "----------\n",
      "epoch time: 0.5458455085754395   total time: 117.80252027511597\n",
      "Epoch 98/9999\n",
      "----------\n",
      "epoch time: 0.5373477935791016   total time: 118.34026622772217\n",
      "Epoch 99/9999\n",
      "----------\n",
      "epoch time: 0.5616998672485352   total time: 118.90247082710266\n",
      "Epoch 100/9999\n",
      "----------\n",
      "loss= 0.5937438325897995 acc= 0.7443946188340808 acctrain= 0.6955056179775281\n",
      "epoch time: 0.8461065292358398   total time: 119.74906158447266\n",
      "Epoch 101/9999\n",
      "----------\n",
      "epoch time: 0.4923546314239502   total time: 120.2414903640747\n",
      "Epoch 102/9999\n",
      "----------\n",
      "epoch time: 0.599062442779541   total time: 120.84081244468689\n",
      "Epoch 103/9999\n",
      "----------\n",
      "epoch time: 0.5516695976257324   total time: 121.39270567893982\n",
      "Epoch 104/9999\n",
      "----------\n",
      "epoch time: 0.5071523189544678   total time: 121.9000186920166\n",
      "Epoch 105/9999\n",
      "----------\n",
      "epoch time: 0.5056660175323486   total time: 122.4059100151062\n",
      "Epoch 106/9999\n",
      "----------\n",
      "epoch time: 0.5615270137786865   total time: 122.9676022529602\n",
      "Epoch 107/9999\n",
      "----------\n",
      "epoch time: 0.5827229022979736   total time: 123.55046916007996\n",
      "Epoch 108/9999\n",
      "----------\n",
      "epoch time: 0.6227037906646729   total time: 124.17432641983032\n",
      "Epoch 109/9999\n",
      "----------\n",
      "epoch time: 0.7235982418060303   total time: 124.89812636375427\n",
      "Epoch 110/9999\n",
      "----------\n",
      "loss= 0.5868062747166296 acc= 0.7399103139013453 acctrain= 0.6898876404494382\n",
      "epoch time: 2.203925371170044   total time: 127.10237789154053\n",
      "Epoch 111/9999\n",
      "----------\n",
      "epoch time: 1.4046878814697266   total time: 128.5075283050537\n",
      "Epoch 112/9999\n",
      "----------\n",
      "epoch time: 1.4179182052612305   total time: 129.92570233345032\n",
      "Epoch 113/9999\n",
      "----------\n",
      "epoch time: 1.549246072769165   total time: 131.4751100540161\n",
      "Epoch 114/9999\n",
      "----------\n",
      "epoch time: 1.4710805416107178   total time: 132.94648575782776\n",
      "Epoch 115/9999\n",
      "----------\n",
      "epoch time: 1.541172742843628   total time: 134.48801565170288\n",
      "Epoch 116/9999\n",
      "----------\n",
      "epoch time: 1.49737548828125   total time: 135.98631715774536\n",
      "Epoch 117/9999\n",
      "----------\n",
      "epoch time: 1.5076656341552734   total time: 137.49421954154968\n",
      "Epoch 118/9999\n",
      "----------\n",
      "epoch time: 1.837021827697754   total time: 139.3317174911499\n",
      "Epoch 119/9999\n",
      "----------\n",
      "epoch time: 1.4879510402679443   total time: 140.81993556022644\n",
      "Epoch 120/9999\n",
      "----------\n",
      "loss= 0.5868596554203418 acc= 0.7399103139013453 acctrain= 0.6910112359550562\n",
      "epoch time: 2.2625322341918945   total time: 143.0827956199646\n",
      "Epoch 121/9999\n",
      "----------\n",
      "epoch time: 1.3824453353881836   total time: 144.4653034210205\n",
      "Epoch 122/9999\n",
      "----------\n",
      "epoch time: 1.6374280452728271   total time: 146.10398316383362\n",
      "Epoch 123/9999\n",
      "----------\n",
      "epoch time: 1.7165470123291016   total time: 147.82120656967163\n",
      "Epoch 124/9999\n",
      "----------\n",
      "epoch time: 1.6740882396697998   total time: 149.4958381652832\n",
      "Epoch 125/9999\n",
      "----------\n",
      "epoch time: 1.8532917499542236   total time: 151.3496413230896\n",
      "Epoch 126/9999\n",
      "----------\n",
      "epoch time: 1.7268505096435547   total time: 153.07788252830505\n",
      "Epoch 127/9999\n",
      "----------\n",
      "epoch time: 1.6060707569122314   total time: 154.68501019477844\n",
      "Epoch 128/9999\n",
      "----------\n",
      "epoch time: 1.1958394050598145   total time: 155.88115787506104\n",
      "Epoch 129/9999\n",
      "----------\n",
      "epoch time: 1.4153919219970703   total time: 157.29688596725464\n",
      "Epoch 130/9999\n",
      "----------\n",
      "loss= 0.5883142454340854 acc= 0.7399103139013453 acctrain= 0.6932584269662921\n",
      "epoch time: 2.3745193481445312   total time: 159.67164754867554\n",
      "Epoch 131/9999\n",
      "----------\n",
      "epoch time: 1.4821126461029053   total time: 161.15436482429504\n",
      "Epoch 132/9999\n",
      "----------\n",
      "epoch time: 1.3991622924804688   total time: 162.5537326335907\n",
      "Epoch 133/9999\n",
      "----------\n",
      "epoch time: 1.4620561599731445   total time: 164.01597619056702\n",
      "Epoch 134/9999\n",
      "----------\n",
      "epoch time: 0.6454694271087646   total time: 164.66167974472046\n",
      "Epoch 135/9999\n",
      "----------\n",
      "epoch time: 0.5601356029510498   total time: 165.22201442718506\n",
      "Epoch 136/9999\n",
      "----------\n",
      "epoch time: 0.493924617767334   total time: 165.71615409851074\n",
      "Epoch 137/9999\n",
      "----------\n",
      "epoch time: 0.46459293365478516   total time: 166.18126106262207\n",
      "Epoch 138/9999\n",
      "----------\n",
      "epoch time: 0.5039594173431396   total time: 166.68533325195312\n",
      "Epoch 139/9999\n",
      "----------\n",
      "epoch time: 0.5699155330657959   total time: 167.255619764328\n",
      "Epoch 140/9999\n",
      "----------\n",
      "loss= 0.587007257168603 acc= 0.7533632286995515 acctrain= 0.701123595505618\n",
      "epoch time: 0.788383960723877   total time: 168.0443844795227\n",
      "Epoch 141/9999\n",
      "----------\n",
      "epoch time: 0.500114917755127   total time: 168.54487991333008\n",
      "Epoch 142/9999\n",
      "----------\n",
      "epoch time: 0.5669794082641602   total time: 169.11224794387817\n",
      "Epoch 143/9999\n",
      "----------\n",
      "epoch time: 0.5503990650177002   total time: 169.66298723220825\n",
      "Epoch 144/9999\n",
      "----------\n",
      "epoch time: 0.5051887035369873   total time: 170.1683053970337\n",
      "Epoch 145/9999\n",
      "----------\n",
      "epoch time: 0.5778329372406006   total time: 170.74627256393433\n",
      "Epoch 146/9999\n",
      "----------\n",
      "epoch time: 1.302222490310669   total time: 172.04967403411865\n",
      "Epoch 147/9999\n",
      "----------\n",
      "epoch time: 1.4773578643798828   total time: 173.52792882919312\n",
      "Epoch 148/9999\n",
      "----------\n",
      "epoch time: 1.4289054870605469   total time: 174.95742416381836\n",
      "Epoch 149/9999\n",
      "----------\n",
      "epoch time: 1.4490625858306885   total time: 176.40662217140198\n",
      "Epoch 150/9999\n",
      "----------\n",
      "loss= 0.5857462735988634 acc= 0.757847533632287 acctrain= 0.697752808988764\n",
      "epoch time: 2.2216062545776367   total time: 178.6285846233368\n",
      "Epoch 151/9999\n",
      "----------\n",
      "epoch time: 1.4085781574249268   total time: 180.03723192214966\n",
      "Epoch 152/9999\n",
      "----------\n",
      "epoch time: 1.5204191207885742   total time: 181.5581831932068\n",
      "Epoch 153/9999\n",
      "----------\n",
      "epoch time: 1.310523509979248   total time: 182.8688349723816\n",
      "Epoch 154/9999\n",
      "----------\n",
      "epoch time: 1.4076769351959229   total time: 184.27664065361023\n",
      "Epoch 155/9999\n",
      "----------\n",
      "epoch time: 1.329246997833252   total time: 185.6060221195221\n",
      "Epoch 156/9999\n",
      "----------\n",
      "epoch time: 1.4117481708526611   total time: 187.01799964904785\n",
      "Epoch 157/9999\n",
      "----------\n",
      "epoch time: 1.3955755233764648   total time: 188.41412138938904\n",
      "Epoch 158/9999\n",
      "----------\n",
      "epoch time: 1.3393058776855469   total time: 189.75357913970947\n",
      "Epoch 159/9999\n",
      "----------\n",
      "epoch time: 1.4510595798492432   total time: 191.2047688961029\n",
      "Epoch 160/9999\n",
      "----------\n",
      "loss= 0.5842678151991335 acc= 0.7533632286995515 acctrain= 0.702247191011236\n",
      "epoch time: 2.6280431747436523   total time: 193.83317756652832\n",
      "Epoch 161/9999\n",
      "----------\n",
      "epoch time: 2.166605234146118   total time: 196.00009632110596\n",
      "Epoch 162/9999\n",
      "----------\n",
      "epoch time: 2.1454272270202637   total time: 198.1456949710846\n",
      "Epoch 163/9999\n",
      "----------\n",
      "epoch time: 1.6595125198364258   total time: 199.80588340759277\n",
      "Epoch 164/9999\n",
      "----------\n",
      "epoch time: 1.3553526401519775   total time: 201.16137433052063\n",
      "Epoch 165/9999\n",
      "----------\n",
      "epoch time: 1.4185385704040527   total time: 202.58054041862488\n",
      "Epoch 166/9999\n",
      "----------\n",
      "epoch time: 1.4783916473388672   total time: 204.05925869941711\n",
      "Epoch 167/9999\n",
      "----------\n",
      "epoch time: 1.475773572921753   total time: 205.5356364250183\n",
      "Epoch 168/9999\n",
      "----------\n",
      "epoch time: 1.52559494972229   total time: 207.06146788597107\n",
      "Epoch 169/9999\n",
      "----------\n",
      "epoch time: 1.404386043548584   total time: 208.4667844772339\n",
      "Epoch 170/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.584457459872079 acc= 0.757847533632287 acctrain= 0.7\n",
      "epoch time: 1.7793936729431152   total time: 210.24641180038452\n",
      "Epoch 171/9999\n",
      "----------\n",
      "epoch time: 0.5194783210754395   total time: 210.7659854888916\n",
      "Epoch 172/9999\n",
      "----------\n",
      "epoch time: 0.5126495361328125   total time: 211.27890372276306\n",
      "Epoch 173/9999\n",
      "----------\n",
      "epoch time: 0.5027773380279541   total time: 211.7820770740509\n",
      "Epoch 174/9999\n",
      "----------\n",
      "epoch time: 0.48230743408203125   total time: 212.2645001411438\n",
      "Epoch 175/9999\n",
      "----------\n",
      "epoch time: 0.5258870124816895   total time: 212.7905251979828\n",
      "Epoch 176/9999\n",
      "----------\n",
      "epoch time: 0.5007750988006592   total time: 213.2914535999298\n",
      "Epoch 177/9999\n",
      "----------\n",
      "epoch time: 0.4686722755432129   total time: 213.76046776771545\n",
      "Epoch 178/9999\n",
      "----------\n",
      "epoch time: 0.5003931522369385   total time: 214.2610263824463\n",
      "Epoch 179/9999\n",
      "----------\n",
      "epoch time: 0.5791959762573242   total time: 214.84038257598877\n",
      "Epoch 180/9999\n",
      "----------\n",
      "loss= 0.5825879585849865 acc= 0.757847533632287 acctrain= 0.7056179775280899\n",
      "epoch time: 0.8258335590362549   total time: 215.6663429737091\n",
      "Epoch 181/9999\n",
      "----------\n",
      "epoch time: 1.0741479396820068   total time: 216.7409541606903\n",
      "Epoch 182/9999\n",
      "----------\n",
      "epoch time: 1.4225621223449707   total time: 218.1640591621399\n",
      "Epoch 183/9999\n",
      "----------\n",
      "epoch time: 1.5587272644042969   total time: 219.72306275367737\n",
      "Epoch 184/9999\n",
      "----------\n",
      "epoch time: 1.4180207252502441   total time: 221.14194321632385\n",
      "Epoch 185/9999\n",
      "----------\n",
      "epoch time: 1.410445213317871   total time: 222.55250453948975\n",
      "Epoch 186/9999\n",
      "----------\n",
      "epoch time: 1.3660874366760254   total time: 223.9187204837799\n",
      "Epoch 187/9999\n",
      "----------\n",
      "epoch time: 1.458310604095459   total time: 225.37733936309814\n",
      "Epoch 188/9999\n",
      "----------\n",
      "epoch time: 1.4936988353729248   total time: 226.8713674545288\n",
      "Epoch 189/9999\n",
      "----------\n",
      "epoch time: 1.399369716644287   total time: 228.27084279060364\n",
      "Epoch 190/9999\n",
      "----------\n",
      "loss= 0.5826891848458303 acc= 0.7533632286995515 acctrain= 0.7078651685393258\n",
      "epoch time: 2.2953040599823   total time: 230.56633257865906\n",
      "Epoch 191/9999\n",
      "----------\n",
      "epoch time: 1.3902218341827393   total time: 231.95713567733765\n",
      "Epoch 192/9999\n",
      "----------\n",
      "epoch time: 1.4812607765197754   total time: 233.4387538433075\n",
      "Epoch 193/9999\n",
      "----------\n",
      "epoch time: 1.4953663349151611   total time: 234.9344038963318\n",
      "Epoch 194/9999\n",
      "----------\n",
      "epoch time: 1.4295547008514404   total time: 236.36410808563232\n",
      "Epoch 195/9999\n",
      "----------\n",
      "epoch time: 1.6949434280395508   total time: 238.05920338630676\n",
      "Epoch 196/9999\n",
      "----------\n",
      "epoch time: 1.6868796348571777   total time: 239.7463662624359\n",
      "Epoch 197/9999\n",
      "----------\n",
      "epoch time: 1.7422504425048828   total time: 241.4887306690216\n",
      "Epoch 198/9999\n",
      "----------\n",
      "epoch time: 1.738297700881958   total time: 243.22717094421387\n",
      "Epoch 199/9999\n",
      "----------\n",
      "epoch time: 1.7267303466796875   total time: 244.95429372787476\n",
      "Epoch 200/9999\n",
      "----------\n",
      "loss= 0.5791024443413645 acc= 0.7399103139013453 acctrain= 0.7078651685393258\n",
      "epoch time: 2.307879686355591   total time: 247.26296401023865\n",
      "Epoch 201/9999\n",
      "----------\n",
      "epoch time: 1.4171829223632812   total time: 248.6802065372467\n",
      "Epoch 202/9999\n",
      "----------\n",
      "epoch time: 1.3360035419464111   total time: 250.01660180091858\n",
      "Epoch 203/9999\n",
      "----------\n",
      "epoch time: 1.365692377090454   total time: 251.38250613212585\n",
      "Epoch 204/9999\n",
      "----------\n",
      "epoch time: 1.4276173114776611   total time: 252.8108971118927\n",
      "Epoch 205/9999\n",
      "----------\n",
      "epoch time: 1.4539999961853027   total time: 254.26509308815002\n",
      "Epoch 206/9999\n",
      "----------\n",
      "epoch time: 1.2044329643249512   total time: 255.46972608566284\n",
      "Epoch 207/9999\n",
      "----------\n",
      "epoch time: 0.5381262302398682   total time: 256.0084345340729\n",
      "Epoch 208/9999\n",
      "----------\n",
      "epoch time: 0.5097646713256836   total time: 256.51833319664\n",
      "Epoch 209/9999\n",
      "----------\n",
      "epoch time: 0.6055786609649658   total time: 257.1243417263031\n",
      "Epoch 210/9999\n",
      "----------\n",
      "loss= 0.5752818883133576 acc= 0.7309417040358744 acctrain= 0.7134831460674157\n",
      "epoch time: 0.7859086990356445   total time: 257.9104013442993\n",
      "Epoch 211/9999\n",
      "----------\n",
      "epoch time: 0.6178267002105713   total time: 258.52829813957214\n",
      "Epoch 212/9999\n",
      "----------\n",
      "epoch time: 0.5210697650909424   total time: 259.0497136116028\n",
      "Epoch 213/9999\n",
      "----------\n",
      "epoch time: 0.5094180107116699   total time: 259.55929255485535\n",
      "Epoch 214/9999\n",
      "----------\n",
      "epoch time: 0.5756518840789795   total time: 260.1351454257965\n",
      "Epoch 215/9999\n",
      "----------\n",
      "epoch time: 0.6180036067962646   total time: 260.75365567207336\n",
      "Epoch 216/9999\n",
      "----------\n",
      "epoch time: 0.6470122337341309   total time: 261.40080094337463\n",
      "Epoch 217/9999\n",
      "----------\n",
      "epoch time: 0.5291969776153564   total time: 261.9301302433014\n",
      "Epoch 218/9999\n",
      "----------\n",
      "epoch time: 0.46482181549072266   total time: 262.395471572876\n",
      "Epoch 219/9999\n",
      "----------\n",
      "epoch time: 0.4846229553222656   total time: 262.8806059360504\n",
      "Epoch 220/9999\n",
      "----------\n",
      "loss= 0.5761726213944867 acc= 0.7533632286995515 acctrain= 0.7078651685393258\n",
      "epoch time: 0.7916224002838135   total time: 263.67237877845764\n",
      "Epoch 221/9999\n",
      "----------\n",
      "epoch time: 0.4641101360321045   total time: 264.13656640052795\n",
      "Epoch 222/9999\n",
      "----------\n",
      "epoch time: 0.5145952701568604   total time: 264.65197563171387\n",
      "Epoch 223/9999\n",
      "----------\n",
      "epoch time: 0.5131561756134033   total time: 265.1652796268463\n",
      "Epoch 224/9999\n",
      "----------\n",
      "epoch time: 0.4822845458984375   total time: 265.6476995944977\n",
      "Epoch 225/9999\n",
      "----------\n",
      "epoch time: 1.1306657791137695   total time: 266.7787871360779\n",
      "Epoch 226/9999\n",
      "----------\n",
      "epoch time: 1.3958430290222168   total time: 268.1748857498169\n",
      "Epoch 227/9999\n",
      "----------\n",
      "epoch time: 1.4934349060058594   total time: 269.6684820652008\n",
      "Epoch 228/9999\n",
      "----------\n",
      "epoch time: 1.4545435905456543   total time: 271.1231813430786\n",
      "Epoch 229/9999\n",
      "----------\n",
      "epoch time: 1.3958995342254639   total time: 272.51960587501526\n",
      "Epoch 230/9999\n",
      "----------\n",
      "loss= 0.5767810060037091 acc= 0.7533632286995515 acctrain= 0.7067415730337079\n",
      "epoch time: 2.174654960632324   total time: 274.69471740722656\n",
      "Epoch 231/9999\n",
      "----------\n",
      "epoch time: 1.551530361175537   total time: 276.2472138404846\n",
      "Epoch 232/9999\n",
      "----------\n",
      "epoch time: 1.1599524021148682   total time: 277.40734481811523\n",
      "Epoch 233/9999\n",
      "----------\n",
      "epoch time: 1.4515883922576904   total time: 278.8593153953552\n",
      "Epoch 234/9999\n",
      "----------\n",
      "epoch time: 1.366614580154419   total time: 280.2260751724243\n",
      "Epoch 235/9999\n",
      "----------\n",
      "epoch time: 1.4471564292907715   total time: 281.6733989715576\n",
      "Epoch 236/9999\n",
      "----------\n",
      "epoch time: 1.3794734477996826   total time: 283.0530204772949\n",
      "Epoch 237/9999\n",
      "----------\n",
      "epoch time: 1.3753080368041992   total time: 284.4284806251526\n",
      "Epoch 238/9999\n",
      "----------\n",
      "epoch time: 1.38873291015625   total time: 285.8176257610321\n",
      "Epoch 239/9999\n",
      "----------\n",
      "epoch time: 1.709704875946045   total time: 287.5276551246643\n",
      "Epoch 240/9999\n",
      "----------\n",
      "loss= 0.5763991272636593 acc= 0.7443946188340808 acctrain= 0.7112359550561798\n",
      "epoch time: 2.82708740234375   total time: 290.3549864292145\n",
      "Epoch 241/9999\n",
      "----------\n",
      "epoch time: 1.6800217628479004   total time: 292.0354902744293\n",
      "Epoch 242/9999\n",
      "----------\n",
      "epoch time: 1.7925398349761963   total time: 293.828768491745\n",
      "Epoch 243/9999\n",
      "----------\n",
      "epoch time: 1.6349573135375977   total time: 295.46385169029236\n",
      "Epoch 244/9999\n",
      "----------\n",
      "epoch time: 1.2986762523651123   total time: 296.7626452445984\n",
      "Epoch 245/9999\n",
      "----------\n",
      "epoch time: 1.3888089656829834   total time: 298.1519410610199\n",
      "Epoch 246/9999\n",
      "----------\n",
      "epoch time: 1.386404275894165   total time: 299.5385649204254\n",
      "Epoch 247/9999\n",
      "----------\n",
      "epoch time: 1.3603646755218506   total time: 300.8990762233734\n",
      "Epoch 248/9999\n",
      "----------\n",
      "epoch time: 1.2559609413146973   total time: 302.15547609329224\n",
      "Epoch 249/9999\n",
      "----------\n",
      "epoch time: 1.3872616291046143   total time: 303.5443506240845\n",
      "Epoch 250/9999\n",
      "----------\n",
      "loss= 0.5766977905692541 acc= 0.7354260089686099 acctrain= 0.7134831460674157\n",
      "epoch time: 1.6803925037384033   total time: 305.22488927841187\n",
      "Epoch 251/9999\n",
      "----------\n",
      "epoch time: 0.49403929710388184   total time: 305.718998670578\n",
      "Epoch 252/9999\n",
      "----------\n",
      "epoch time: 0.4969625473022461   total time: 306.2160761356354\n",
      "Epoch 253/9999\n",
      "----------\n",
      "epoch time: 0.4784517288208008   total time: 306.69475197792053\n",
      "Epoch 254/9999\n",
      "----------\n",
      "epoch time: 0.4853696823120117   total time: 307.1804368495941\n",
      "Epoch 255/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time: 0.4774439334869385   total time: 307.65800881385803\n",
      "Epoch 256/9999\n",
      "----------\n",
      "epoch time: 0.5265278816223145   total time: 308.1849901676178\n",
      "Epoch 257/9999\n",
      "----------\n",
      "epoch time: 0.5357503890991211   total time: 308.72089076042175\n",
      "Epoch 258/9999\n",
      "----------\n",
      "epoch time: 0.6059854030609131   total time: 309.3270585536957\n",
      "Epoch 259/9999\n",
      "----------\n",
      "epoch time: 0.6122946739196777   total time: 309.9400055408478\n",
      "Epoch 260/9999\n",
      "----------\n",
      "loss= 0.5761421236623029 acc= 0.7533632286995515 acctrain= 0.7033707865168539\n",
      "epoch time: 0.9165081977844238   total time: 310.85687351226807\n",
      "Epoch 261/9999\n",
      "----------\n",
      "epoch time: 0.46782922744750977   total time: 311.32476711273193\n",
      "Epoch 262/9999\n",
      "----------\n",
      "epoch time: 0.5655307769775391   total time: 311.8904414176941\n",
      "Epoch 263/9999\n",
      "----------\n",
      "epoch time: 0.5401549339294434   total time: 312.4311056137085\n",
      "Epoch 264/9999\n",
      "----------\n",
      "epoch time: 0.54052734375   total time: 312.9719648361206\n",
      "Epoch 265/9999\n",
      "----------\n",
      "epoch time: 0.5033540725708008   total time: 313.4754457473755\n",
      "Epoch 266/9999\n",
      "----------\n",
      "epoch time: 0.5183258056640625   total time: 313.99408745765686\n",
      "Epoch 267/9999\n",
      "----------\n",
      "epoch time: 0.5039947032928467   total time: 314.4984622001648\n",
      "Epoch 268/9999\n",
      "----------\n",
      "epoch time: 0.6269760131835938   total time: 315.1255748271942\n",
      "Epoch 269/9999\n",
      "----------\n",
      "epoch time: 1.427893877029419   total time: 316.5535957813263\n",
      "Epoch 270/9999\n",
      "----------\n",
      "loss= 0.5744283569500586 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 2.187535047531128   total time: 318.74139046669006\n",
      "Epoch 271/9999\n",
      "----------\n",
      "epoch time: 1.3723087310791016   total time: 320.1137683391571\n",
      "Epoch 272/9999\n",
      "----------\n",
      "epoch time: 1.4060332775115967   total time: 321.51996755599976\n",
      "Epoch 273/9999\n",
      "----------\n",
      "epoch time: 1.4901454448699951   total time: 323.0103316307068\n",
      "Epoch 274/9999\n",
      "----------\n",
      "epoch time: 1.4197351932525635   total time: 324.43028020858765\n",
      "Epoch 275/9999\n",
      "----------\n",
      "epoch time: 1.493180751800537   total time: 325.923654794693\n",
      "Epoch 276/9999\n",
      "----------\n",
      "epoch time: 1.503967523574829   total time: 327.42796874046326\n",
      "Epoch 277/9999\n",
      "----------\n",
      "epoch time: 1.3895883560180664   total time: 328.81786012649536\n",
      "Epoch 278/9999\n",
      "----------\n",
      "epoch time: 1.384321689605713   total time: 330.20245480537415\n",
      "Epoch 279/9999\n",
      "----------\n",
      "epoch time: 1.4577198028564453   total time: 331.6603307723999\n",
      "Epoch 280/9999\n",
      "----------\n",
      "loss= 0.5763077451241925 acc= 0.7488789237668162 acctrain= 0.7033707865168539\n",
      "epoch time: 2.1150851249694824   total time: 333.775826215744\n",
      "Epoch 281/9999\n",
      "----------\n",
      "epoch time: 1.4110491275787354   total time: 335.1879024505615\n",
      "Epoch 282/9999\n",
      "----------\n",
      "epoch time: 1.5462501049041748   total time: 336.73439717292786\n",
      "Epoch 283/9999\n",
      "----------\n",
      "epoch time: 1.7524163722991943   total time: 338.4869258403778\n",
      "Epoch 284/9999\n",
      "----------\n",
      "epoch time: 1.656198501586914   total time: 340.14323902130127\n",
      "Epoch 285/9999\n",
      "----------\n",
      "epoch time: 1.6603646278381348   total time: 341.804146528244\n",
      "Epoch 286/9999\n",
      "----------\n",
      "epoch time: 1.7068212032318115   total time: 343.511079788208\n",
      "Epoch 287/9999\n",
      "----------\n",
      "epoch time: 1.4386770725250244   total time: 344.9506895542145\n",
      "Epoch 288/9999\n",
      "----------\n",
      "epoch time: 1.4383876323699951   total time: 346.38977098464966\n",
      "Epoch 289/9999\n",
      "----------\n",
      "epoch time: 1.6691193580627441   total time: 348.0590167045593\n",
      "Epoch 290/9999\n",
      "----------\n",
      "loss= 0.5743993850165953 acc= 0.7354260089686099 acctrain= 0.7123595505617978\n",
      "epoch time: 2.431525230407715   total time: 350.4906497001648\n",
      "Epoch 291/9999\n",
      "----------\n",
      "epoch time: 1.4149138927459717   total time: 351.9056239128113\n",
      "Epoch 292/9999\n",
      "----------\n",
      "epoch time: 1.4292385578155518   total time: 353.3350212574005\n",
      "Epoch 293/9999\n",
      "----------\n",
      "epoch time: 0.9547820091247559   total time: 354.2900974750519\n",
      "Epoch 294/9999\n",
      "----------\n",
      "epoch time: 0.47560548782348633   total time: 354.7659342288971\n",
      "Epoch 295/9999\n",
      "----------\n",
      "epoch time: 0.5039470195770264   total time: 355.2700502872467\n",
      "Epoch 296/9999\n",
      "----------\n",
      "epoch time: 0.5805003643035889   total time: 355.85070610046387\n",
      "Epoch 297/9999\n",
      "----------\n",
      "epoch time: 0.5533647537231445   total time: 356.40420293807983\n",
      "Epoch 298/9999\n",
      "----------\n",
      "epoch time: 0.526287317276001   total time: 356.93082547187805\n",
      "Epoch 299/9999\n",
      "----------\n",
      "epoch time: 0.5544624328613281   total time: 357.48561787605286\n",
      "Epoch 300/9999\n",
      "----------\n",
      "loss= 0.5729383630469241 acc= 0.7488789237668162 acctrain= 0.7044943820224719\n",
      "epoch time: 0.8588817119598389   total time: 358.34464836120605\n",
      "Epoch 301/9999\n",
      "----------\n",
      "epoch time: 0.4967672824859619   total time: 358.8417594432831\n",
      "Epoch 302/9999\n",
      "----------\n",
      "epoch time: 0.49179744720458984   total time: 359.33378744125366\n",
      "Epoch 303/9999\n",
      "----------\n",
      "epoch time: 0.547276496887207   total time: 359.8816783428192\n",
      "Epoch 304/9999\n",
      "----------\n",
      "epoch time: 0.540114164352417   total time: 360.4221727848053\n",
      "Epoch 305/9999\n",
      "----------\n",
      "epoch time: 1.2798922061920166   total time: 361.7021977901459\n",
      "Epoch 306/9999\n",
      "----------\n",
      "epoch time: 1.370361328125   total time: 363.0730850696564\n",
      "Epoch 307/9999\n",
      "----------\n",
      "epoch time: 1.5029685497283936   total time: 364.576593875885\n",
      "Epoch 308/9999\n",
      "----------\n",
      "epoch time: 1.4817068576812744   total time: 366.0584499835968\n",
      "Epoch 309/9999\n",
      "----------\n",
      "epoch time: 1.4138903617858887   total time: 367.4724600315094\n",
      "Epoch 310/9999\n",
      "----------\n",
      "loss= 0.572104802513871 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 2.1348228454589844   total time: 369.60748744010925\n",
      "Epoch 311/9999\n",
      "----------\n",
      "epoch time: 1.4788408279418945   total time: 371.0865807533264\n",
      "Epoch 312/9999\n",
      "----------\n",
      "epoch time: 1.1550328731536865   total time: 372.2419242858887\n",
      "Epoch 313/9999\n",
      "----------\n",
      "epoch time: 1.2903118133544922   total time: 373.53236532211304\n",
      "Epoch 314/9999\n",
      "----------\n",
      "epoch time: 1.3356518745422363   total time: 374.86812949180603\n",
      "Epoch 315/9999\n",
      "----------\n",
      "epoch time: 1.3895368576049805   total time: 376.2577784061432\n",
      "Epoch 316/9999\n",
      "----------\n",
      "epoch time: 1.3639121055603027   total time: 377.62199425697327\n",
      "Epoch 317/9999\n",
      "----------\n",
      "epoch time: 1.4613561630249023   total time: 379.08404517173767\n",
      "Epoch 318/9999\n",
      "----------\n",
      "epoch time: 1.4625883102416992   total time: 380.546763420105\n",
      "Epoch 319/9999\n",
      "----------\n",
      "epoch time: 1.607429027557373   total time: 382.1544690132141\n",
      "Epoch 320/9999\n",
      "----------\n",
      "loss= 0.5721635174323625 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 2.599320888519287   total time: 384.75412917137146\n",
      "Epoch 321/9999\n",
      "----------\n",
      "epoch time: 1.7390661239624023   total time: 386.49323868751526\n",
      "Epoch 322/9999\n",
      "----------\n",
      "epoch time: 1.5860154628753662   total time: 388.07975244522095\n",
      "Epoch 323/9999\n",
      "----------\n",
      "epoch time: 1.7000291347503662   total time: 389.7801012992859\n",
      "Epoch 324/9999\n",
      "----------\n",
      "epoch time: 1.3325855731964111   total time: 391.1128168106079\n",
      "Epoch 325/9999\n",
      "----------\n",
      "epoch time: 1.3715498447418213   total time: 392.484929561615\n",
      "Epoch 326/9999\n",
      "----------\n",
      "epoch time: 1.4315032958984375   total time: 393.91737246513367\n",
      "Epoch 327/9999\n",
      "----------\n",
      "epoch time: 1.4162499904632568   total time: 395.3341529369354\n",
      "Epoch 328/9999\n",
      "----------\n",
      "epoch time: 1.3535525798797607   total time: 396.6879460811615\n",
      "Epoch 329/9999\n",
      "----------\n",
      "epoch time: 1.4054923057556152   total time: 398.0937194824219\n",
      "Epoch 330/9999\n",
      "----------\n",
      "loss= 0.5719141429582519 acc= 0.7488789237668162 acctrain= 0.7067415730337079\n",
      "epoch time: 1.8597683906555176   total time: 399.95364022254944\n",
      "Epoch 331/9999\n",
      "----------\n",
      "epoch time: 0.4602987766265869   total time: 400.4153916835785\n",
      "Epoch 332/9999\n",
      "----------\n",
      "epoch time: 0.46640729904174805   total time: 400.8819284439087\n",
      "Epoch 333/9999\n",
      "----------\n",
      "epoch time: 0.4633505344390869   total time: 401.3456220626831\n",
      "Epoch 334/9999\n",
      "----------\n",
      "epoch time: 0.4676346778869629   total time: 401.81341195106506\n",
      "Epoch 335/9999\n",
      "----------\n",
      "epoch time: 0.4354116916656494   total time: 402.24893736839294\n",
      "Epoch 336/9999\n",
      "----------\n",
      "epoch time: 0.5200252532958984   total time: 402.76929807662964\n",
      "Epoch 337/9999\n",
      "----------\n",
      "epoch time: 0.5388221740722656   total time: 403.3089814186096\n",
      "Epoch 338/9999\n",
      "----------\n",
      "epoch time: 0.49515700340270996   total time: 403.8042893409729\n",
      "Epoch 339/9999\n",
      "----------\n",
      "epoch time: 0.5095269680023193   total time: 404.31414794921875\n",
      "Epoch 340/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.572913909105442 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 0.7538242340087891   total time: 405.0682828426361\n",
      "Epoch 341/9999\n",
      "----------\n",
      "epoch time: 0.4716637134552002   total time: 405.5401449203491\n",
      "Epoch 342/9999\n",
      "----------\n",
      "epoch time: 0.46379637718200684   total time: 406.0042972564697\n",
      "Epoch 343/9999\n",
      "----------\n",
      "epoch time: 0.5140800476074219   total time: 406.5186665058136\n",
      "Epoch 344/9999\n",
      "----------\n",
      "epoch time: 1.2091045379638672   total time: 407.7279577255249\n",
      "Epoch 345/9999\n",
      "----------\n",
      "epoch time: 1.4465713500976562   total time: 409.17476534843445\n",
      "Epoch 346/9999\n",
      "----------\n",
      "epoch time: 1.3761990070343018   total time: 410.5514872074127\n",
      "Epoch 347/9999\n",
      "----------\n",
      "epoch time: 1.297003984451294   total time: 411.8486044406891\n",
      "Epoch 348/9999\n",
      "----------\n",
      "epoch time: 1.3175420761108398   total time: 413.16647601127625\n",
      "Epoch 349/9999\n",
      "----------\n",
      "epoch time: 1.3126654624938965   total time: 414.4793167114258\n",
      "Epoch 350/9999\n",
      "----------\n",
      "loss= 0.5721910424162989 acc= 0.7399103139013453 acctrain= 0.7089887640449438\n",
      "epoch time: 2.5117387771606445   total time: 416.99158096313477\n",
      "Epoch 351/9999\n",
      "----------\n",
      "epoch time: 1.3138353824615479   total time: 418.3055462837219\n",
      "Epoch 352/9999\n",
      "----------\n",
      "epoch time: 1.822749376296997   total time: 420.1286287307739\n",
      "Epoch 353/9999\n",
      "----------\n",
      "epoch time: 1.595444917678833   total time: 421.72431111335754\n",
      "Epoch 354/9999\n",
      "----------\n",
      "epoch time: 1.471069574356079   total time: 423.1955335140228\n",
      "Epoch 355/9999\n",
      "----------\n",
      "epoch time: 1.3484141826629639   total time: 424.5448455810547\n",
      "Epoch 356/9999\n",
      "----------\n",
      "epoch time: 1.4711525440216064   total time: 426.0164487361908\n",
      "Epoch 357/9999\n",
      "----------\n",
      "epoch time: 1.491443157196045   total time: 427.5080351829529\n",
      "Epoch 358/9999\n",
      "----------\n",
      "epoch time: 1.6860971450805664   total time: 429.19438219070435\n",
      "Epoch 359/9999\n",
      "----------\n",
      "epoch time: 1.780207633972168   total time: 430.9764597415924\n",
      "Epoch 360/9999\n",
      "----------\n",
      "loss= 0.5714481673433107 acc= 0.7488789237668162 acctrain= 0.7044943820224719\n",
      "epoch time: 2.735046863555908   total time: 433.7116470336914\n",
      "Epoch 361/9999\n",
      "----------\n",
      "epoch time: 1.69891357421875   total time: 435.410617351532\n",
      "Epoch 362/9999\n",
      "----------\n",
      "epoch time: 1.4526565074920654   total time: 436.8633830547333\n",
      "Epoch 363/9999\n",
      "----------\n",
      "epoch time: 1.4140043258666992   total time: 438.27749943733215\n",
      "Epoch 364/9999\n",
      "----------\n",
      "epoch time: 1.4846935272216797   total time: 439.7623505592346\n",
      "Epoch 365/9999\n",
      "----------\n",
      "epoch time: 1.4027411937713623   total time: 441.16522097587585\n",
      "Epoch 366/9999\n",
      "----------\n",
      "epoch time: 1.3222343921661377   total time: 442.4877190589905\n",
      "Epoch 367/9999\n",
      "----------\n",
      "epoch time: 1.375253677368164   total time: 443.8631224632263\n",
      "Epoch 368/9999\n",
      "----------\n",
      "epoch time: 1.43418550491333   total time: 445.2974388599396\n",
      "Epoch 369/9999\n",
      "----------\n",
      "epoch time: 0.7980477809906006   total time: 446.095596075058\n",
      "Epoch 370/9999\n",
      "----------\n",
      "loss= 0.5716250798761042 acc= 0.7488789237668162 acctrain= 0.7056179775280899\n",
      "epoch time: 0.6806328296661377   total time: 446.7763385772705\n",
      "Epoch 371/9999\n",
      "----------\n",
      "epoch time: 0.46672677993774414   total time: 447.24339032173157\n",
      "Epoch 372/9999\n",
      "----------\n",
      "epoch time: 0.47333407402038574   total time: 447.71703267097473\n",
      "Epoch 373/9999\n",
      "----------\n",
      "epoch time: 0.4996216297149658   total time: 448.21677589416504\n",
      "Epoch 374/9999\n",
      "----------\n",
      "epoch time: 0.4897732734680176   total time: 448.70666337013245\n",
      "Epoch 375/9999\n",
      "----------\n",
      "epoch time: 0.5743587017059326   total time: 449.28142404556274\n",
      "Epoch 376/9999\n",
      "----------\n",
      "epoch time: 0.4740161895751953   total time: 449.7557454109192\n",
      "Epoch 377/9999\n",
      "----------\n",
      "epoch time: 0.46767401695251465   total time: 450.2235338687897\n",
      "Epoch 378/9999\n",
      "----------\n",
      "epoch time: 0.4922459125518799   total time: 450.7159125804901\n",
      "Epoch 379/9999\n",
      "----------\n",
      "epoch time: 0.4730818271636963   total time: 451.1891031265259\n",
      "Epoch 380/9999\n",
      "----------\n",
      "loss= 0.5722054293203781 acc= 0.7399103139013453 acctrain= 0.7067415730337079\n",
      "epoch time: 0.6842985153198242   total time: 451.8735234737396\n",
      "Epoch 381/9999\n",
      "----------\n",
      "epoch time: 0.4669661521911621   total time: 452.3406271934509\n",
      "Epoch 382/9999\n",
      "----------\n",
      "epoch time: 1.1084778308868408   total time: 453.44964694976807\n",
      "Epoch 383/9999\n",
      "----------\n",
      "epoch time: 1.4223618507385254   total time: 454.87215280532837\n",
      "Epoch 384/9999\n",
      "----------\n",
      "epoch time: 1.4628231525421143   total time: 456.3352372646332\n",
      "Epoch 385/9999\n",
      "----------\n",
      "epoch time: 1.4487757682800293   total time: 457.7843232154846\n",
      "Epoch 386/9999\n",
      "----------\n",
      "epoch time: 1.510880708694458   total time: 459.2957389354706\n",
      "Epoch 387/9999\n",
      "----------\n",
      "epoch time: 1.5446736812591553   total time: 460.84119296073914\n",
      "Epoch 388/9999\n",
      "----------\n",
      "epoch time: 1.4549803733825684   total time: 462.29645442962646\n",
      "Epoch 389/9999\n",
      "----------\n",
      "epoch time: 1.411299467086792   total time: 463.7078719139099\n",
      "Epoch 390/9999\n",
      "----------\n",
      "loss= 0.571055796782532 acc= 0.7488789237668162 acctrain= 0.7056179775280899\n",
      "epoch time: 2.142766237258911   total time: 465.85116147994995\n",
      "Epoch 391/9999\n",
      "----------\n",
      "epoch time: 1.4387521743774414   total time: 467.2905447483063\n",
      "Epoch 392/9999\n",
      "----------\n",
      "epoch time: 1.4577116966247559   total time: 468.74851846694946\n",
      "Epoch 393/9999\n",
      "----------\n",
      "epoch time: 1.437227725982666   total time: 470.18586468696594\n",
      "Epoch 394/9999\n",
      "----------\n",
      "epoch time: 1.4807703495025635   total time: 471.6669042110443\n",
      "Epoch 395/9999\n",
      "----------\n",
      "epoch time: 1.5044255256652832   total time: 473.17145133018494\n",
      "Epoch 396/9999\n",
      "----------\n",
      "epoch time: 1.66166353225708   total time: 474.8337664604187\n",
      "Epoch 397/9999\n",
      "----------\n",
      "epoch time: 1.6410417556762695   total time: 476.4749414920807\n",
      "Epoch 398/9999\n",
      "----------\n",
      "epoch time: 1.7175486087799072   total time: 478.19319200515747\n",
      "Epoch 399/9999\n",
      "----------\n",
      "epoch time: 1.7913744449615479   total time: 479.98490500450134\n",
      "Epoch 400/9999\n",
      "----------\n",
      "loss= 0.5707043468150322 acc= 0.7488789237668162 acctrain= 0.7078651685393258\n",
      "epoch time: 2.125819444656372   total time: 482.11184096336365\n",
      "Epoch 401/9999\n",
      "----------\n",
      "epoch time: 1.3191697597503662   total time: 483.4311079978943\n",
      "Epoch 402/9999\n",
      "----------\n",
      "epoch time: 1.431490421295166   total time: 484.8628170490265\n",
      "Epoch 403/9999\n",
      "----------\n",
      "epoch time: 1.7301790714263916   total time: 486.5931351184845\n",
      "Epoch 404/9999\n",
      "----------\n",
      "epoch time: 1.489065408706665   total time: 488.0825216770172\n",
      "Epoch 405/9999\n",
      "----------\n",
      "epoch time: 1.3961966037750244   total time: 489.47900581359863\n",
      "Epoch 406/9999\n",
      "----------\n",
      "epoch time: 0.7840940952301025   total time: 490.26325392723083\n",
      "Epoch 407/9999\n",
      "----------\n",
      "epoch time: 0.4978926181793213   total time: 490.761253118515\n",
      "Epoch 408/9999\n",
      "----------\n",
      "epoch time: 0.5204951763153076   total time: 491.2818932533264\n",
      "Epoch 409/9999\n",
      "----------\n",
      "epoch time: 0.45949316024780273   total time: 491.7416980266571\n",
      "Epoch 410/9999\n",
      "----------\n",
      "loss= 0.5706262440157578 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 0.7746200561523438   total time: 492.5166001319885\n",
      "Epoch 411/9999\n",
      "----------\n",
      "epoch time: 0.4784376621246338   total time: 492.99532413482666\n",
      "Epoch 412/9999\n",
      "----------\n",
      "epoch time: 0.5049667358398438   total time: 493.50078320503235\n",
      "Epoch 413/9999\n",
      "----------\n",
      "epoch time: 0.4815342426300049   total time: 493.98247265815735\n",
      "Epoch 414/9999\n",
      "----------\n",
      "epoch time: 0.5101659297943115   total time: 494.4927706718445\n",
      "Epoch 415/9999\n",
      "----------\n",
      "epoch time: 0.5325255393981934   total time: 495.025422334671\n",
      "Epoch 416/9999\n",
      "----------\n",
      "epoch time: 0.5037424564361572   total time: 495.5296094417572\n",
      "Epoch 417/9999\n",
      "----------\n",
      "epoch time: 0.46016454696655273   total time: 495.98991537094116\n",
      "Epoch 418/9999\n",
      "----------\n",
      "epoch time: 0.49793243408203125   total time: 496.48799657821655\n",
      "Epoch 419/9999\n",
      "----------\n",
      "epoch time: 0.4494295120239258   total time: 496.93757486343384\n",
      "Epoch 420/9999\n",
      "----------\n",
      "loss= 0.5707258983043277 acc= 0.7443946188340808 acctrain= 0.7056179775280899\n",
      "epoch time: 0.6742515563964844   total time: 497.6119418144226\n",
      "Epoch 421/9999\n",
      "----------\n",
      "epoch time: 0.46722888946533203   total time: 498.0794129371643\n",
      "Epoch 422/9999\n",
      "----------\n",
      "epoch time: 0.4740428924560547   total time: 498.5535809993744\n",
      "Epoch 423/9999\n",
      "----------\n",
      "epoch time: 0.6292984485626221   total time: 499.1830065250397\n",
      "Epoch 424/9999\n",
      "----------\n",
      "epoch time: 1.3234186172485352   total time: 500.50692534446716\n",
      "Epoch 425/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time: 1.4099133014678955   total time: 501.91695284843445\n",
      "Epoch 426/9999\n",
      "----------\n",
      "epoch time: 1.4247498512268066   total time: 503.34189319610596\n",
      "Epoch 427/9999\n",
      "----------\n",
      "epoch time: 1.4657926559448242   total time: 504.808039188385\n",
      "Epoch 428/9999\n",
      "----------\n",
      "epoch time: 1.4293758869171143   total time: 506.2377030849457\n",
      "Epoch 429/9999\n",
      "----------\n",
      "epoch time: 1.3658709526062012   total time: 507.603716135025\n",
      "Epoch 430/9999\n",
      "----------\n",
      "loss= 0.5710875113983326 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 2.0850934982299805   total time: 509.68937611579895\n",
      "Epoch 431/9999\n",
      "----------\n",
      "epoch time: 1.3025732040405273   total time: 510.9921598434448\n",
      "Epoch 432/9999\n",
      "----------\n",
      "epoch time: 1.424088478088379   total time: 512.4178457260132\n",
      "Epoch 433/9999\n",
      "----------\n",
      "epoch time: 1.4543027877807617   total time: 513.8725848197937\n",
      "Epoch 434/9999\n",
      "----------\n",
      "epoch time: 1.3796277046203613   total time: 515.2526650428772\n",
      "Epoch 435/9999\n",
      "----------\n",
      "epoch time: 1.4731647968292236   total time: 516.7259726524353\n",
      "Epoch 436/9999\n",
      "----------\n",
      "epoch time: 1.3696858882904053   total time: 518.0960204601288\n",
      "Epoch 437/9999\n",
      "----------\n",
      "epoch time: 1.4328556060791016   total time: 519.5290012359619\n",
      "Epoch 438/9999\n",
      "----------\n",
      "epoch time: 1.6982650756835938   total time: 521.2274036407471\n",
      "Epoch 439/9999\n",
      "----------\n",
      "epoch time: 1.6883795261383057   total time: 522.9165523052216\n",
      "Epoch 440/9999\n",
      "----------\n",
      "loss= 0.572390791078854 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 2.605573892593384   total time: 525.522242307663\n",
      "Epoch 441/9999\n",
      "----------\n",
      "epoch time: 1.7611033916473389   total time: 527.2834782600403\n",
      "Epoch 442/9999\n",
      "----------\n",
      "epoch time: 1.5023107528686523   total time: 528.7860851287842\n",
      "Epoch 443/9999\n",
      "----------\n",
      "epoch time: 1.331813097000122   total time: 530.118236541748\n",
      "Epoch 444/9999\n",
      "----------\n",
      "epoch time: 1.4030632972717285   total time: 531.5214130878448\n",
      "Epoch 445/9999\n",
      "----------\n",
      "epoch time: 1.3717479705810547   total time: 532.8932881355286\n",
      "Epoch 446/9999\n",
      "----------\n",
      "epoch time: 1.3863637447357178   total time: 534.2797667980194\n",
      "Epoch 447/9999\n",
      "----------\n",
      "epoch time: 1.4280180931091309   total time: 535.7087013721466\n",
      "Epoch 448/9999\n",
      "----------\n",
      "epoch time: 1.2957558631896973   total time: 537.004781961441\n",
      "Epoch 449/9999\n",
      "----------\n",
      "epoch time: 1.1457915306091309   total time: 538.1506865024567\n",
      "Epoch 450/9999\n",
      "----------\n",
      "loss= 0.5708338364357372 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 0.6785392761230469   total time: 538.8293735980988\n",
      "Epoch 451/9999\n",
      "----------\n",
      "epoch time: 0.47270727157592773   total time: 539.30233335495\n",
      "Epoch 452/9999\n",
      "----------\n",
      "epoch time: 0.5441997051239014   total time: 539.846887588501\n",
      "Epoch 453/9999\n",
      "----------\n",
      "epoch time: 0.5351746082305908   total time: 540.3821902275085\n",
      "Epoch 454/9999\n",
      "----------\n",
      "epoch time: 0.508671760559082   total time: 540.8915071487427\n",
      "Epoch 455/9999\n",
      "----------\n",
      "epoch time: 0.5386362075805664   total time: 541.4303293228149\n",
      "Epoch 456/9999\n",
      "----------\n",
      "epoch time: 0.5373764038085938   total time: 541.9678783416748\n",
      "Epoch 457/9999\n",
      "----------\n",
      "epoch time: 0.44561195373535156   total time: 542.4136211872101\n",
      "Epoch 458/9999\n",
      "----------\n",
      "epoch time: 0.5335454940795898   total time: 542.947304725647\n",
      "Epoch 459/9999\n",
      "----------\n",
      "epoch time: 0.5724937915802002   total time: 543.5199313163757\n",
      "Epoch 460/9999\n",
      "----------\n",
      "loss= 0.5717811386681458 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 1.0967638492584229   total time: 544.6168265342712\n",
      "Epoch 461/9999\n",
      "----------\n",
      "epoch time: 1.4132535457611084   total time: 546.0315508842468\n",
      "Epoch 462/9999\n",
      "----------\n",
      "epoch time: 1.4911644458770752   total time: 547.5228424072266\n",
      "Epoch 463/9999\n",
      "----------\n",
      "epoch time: 1.5265517234802246   total time: 549.049694776535\n",
      "Epoch 464/9999\n",
      "----------\n",
      "epoch time: 1.463721513748169   total time: 550.5137054920197\n",
      "Epoch 465/9999\n",
      "----------\n",
      "epoch time: 1.444915771484375   total time: 551.9589123725891\n",
      "Epoch 466/9999\n",
      "----------\n",
      "epoch time: 1.3729205131530762   total time: 553.3319938182831\n",
      "Epoch 467/9999\n",
      "----------\n",
      "epoch time: 1.5590298175811768   total time: 554.8913369178772\n",
      "Epoch 468/9999\n",
      "----------\n",
      "epoch time: 1.1864736080169678   total time: 556.0786004066467\n",
      "Epoch 469/9999\n",
      "----------\n",
      "epoch time: 1.5319554805755615   total time: 557.6107625961304\n",
      "Epoch 470/9999\n",
      "----------\n",
      "loss= 0.5708709487465999 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 2.5723459720611572   total time: 560.1832222938538\n",
      "Epoch 471/9999\n",
      "----------\n",
      "epoch time: 1.361276626586914   total time: 561.5445594787598\n",
      "Epoch 472/9999\n",
      "----------\n",
      "epoch time: 1.5362799167633057   total time: 563.0811853408813\n",
      "Epoch 473/9999\n",
      "----------\n",
      "epoch time: 1.4137086868286133   total time: 564.4957706928253\n",
      "Epoch 474/9999\n",
      "----------\n",
      "epoch time: 1.71315336227417   total time: 566.2097382545471\n",
      "Epoch 475/9999\n",
      "----------\n",
      "epoch time: 1.6891014575958252   total time: 567.8992073535919\n",
      "Epoch 476/9999\n",
      "----------\n",
      "epoch time: 1.6895020008087158   total time: 569.58895611763\n",
      "Epoch 477/9999\n",
      "----------\n",
      "epoch time: 1.817793369293213   total time: 571.4076135158539\n",
      "Epoch 478/9999\n",
      "----------\n",
      "epoch time: 1.7565639019012451   total time: 573.1643078327179\n",
      "Epoch 479/9999\n",
      "----------\n",
      "epoch time: 1.823826789855957   total time: 574.988440990448\n",
      "Epoch 480/9999\n",
      "----------\n",
      "loss= 0.5706088048460237 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 2.127488136291504   total time: 577.1162190437317\n",
      "Epoch 481/9999\n",
      "----------\n",
      "epoch time: 1.504953384399414   total time: 578.6220009326935\n",
      "Epoch 482/9999\n",
      "----------\n",
      "epoch time: 1.4118642807006836   total time: 580.0342683792114\n",
      "Epoch 483/9999\n",
      "----------\n",
      "epoch time: 1.3777439594268799   total time: 581.4124050140381\n",
      "Epoch 484/9999\n",
      "----------\n",
      "epoch time: 1.3816492557525635   total time: 582.7949833869934\n",
      "Epoch 485/9999\n",
      "----------\n",
      "epoch time: 1.431319236755371   total time: 584.2264506816864\n",
      "Epoch 486/9999\n",
      "----------\n",
      "epoch time: 1.0794196128845215   total time: 585.3060548305511\n",
      "Epoch 487/9999\n",
      "----------\n",
      "epoch time: 0.45453977584838867   total time: 585.760734796524\n",
      "Epoch 488/9999\n",
      "----------\n",
      "epoch time: 0.4964172840118408   total time: 586.2572972774506\n",
      "Epoch 489/9999\n",
      "----------\n",
      "epoch time: 0.5132691860198975   total time: 586.7711174488068\n",
      "Epoch 490/9999\n",
      "----------\n",
      "loss= 0.571763567659887 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 0.7912037372589111   total time: 587.5624494552612\n",
      "Epoch 491/9999\n",
      "----------\n",
      "epoch time: 0.5022706985473633   total time: 588.0648529529572\n",
      "Epoch 492/9999\n",
      "----------\n",
      "epoch time: 0.4992942810058594   total time: 588.5646016597748\n",
      "Epoch 493/9999\n",
      "----------\n",
      "epoch time: 0.4675610065460205   total time: 589.0326554775238\n",
      "Epoch 494/9999\n",
      "----------\n",
      "epoch time: 0.5628607273101807   total time: 589.5959758758545\n",
      "Epoch 495/9999\n",
      "----------\n",
      "epoch time: 0.5320389270782471   total time: 590.1282172203064\n",
      "Epoch 496/9999\n",
      "----------\n",
      "epoch time: 0.522730827331543   total time: 590.6512260437012\n",
      "Epoch 497/9999\n",
      "----------\n",
      "epoch time: 0.47324180603027344   total time: 591.1252727508545\n",
      "Epoch 498/9999\n",
      "----------\n",
      "epoch time: 0.48514652252197266   total time: 591.6107485294342\n",
      "Epoch 499/9999\n",
      "----------\n",
      "epoch time: 0.46918296813964844   total time: 592.0802621841431\n",
      "Epoch 500/9999\n",
      "----------\n",
      "loss= 0.5710581823715715 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 1.3084831237792969   total time: 593.3889236450195\n",
      "Epoch 501/9999\n",
      "----------\n",
      "epoch time: 1.4856879711151123   total time: 594.8746948242188\n",
      "Epoch 502/9999\n",
      "----------\n",
      "epoch time: 1.4351098537445068   total time: 596.3100147247314\n",
      "Epoch 503/9999\n",
      "----------\n",
      "epoch time: 1.3745112419128418   total time: 597.6848499774933\n",
      "Epoch 504/9999\n",
      "----------\n",
      "epoch time: 1.3679125308990479   total time: 599.0528752803802\n",
      "Epoch 505/9999\n",
      "----------\n",
      "epoch time: 1.36368727684021   total time: 600.4167625904083\n",
      "Epoch 506/9999\n",
      "----------\n",
      "epoch time: 1.4204716682434082   total time: 601.8373761177063\n",
      "Epoch 507/9999\n",
      "----------\n",
      "epoch time: 1.5061192512512207   total time: 603.3443658351898\n",
      "Epoch 508/9999\n",
      "----------\n",
      "epoch time: 1.2022895812988281   total time: 604.5468218326569\n",
      "Epoch 509/9999\n",
      "----------\n",
      "epoch time: 1.350304126739502   total time: 605.8976583480835\n",
      "Epoch 510/9999\n",
      "----------\n",
      "loss= 0.5707139455015884 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 2.54369854927063   total time: 608.4414837360382\n",
      "Epoch 511/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time: 1.588639259338379   total time: 610.0301861763\n",
      "Epoch 512/9999\n",
      "----------\n",
      "epoch time: 1.4069523811340332   total time: 611.4376096725464\n",
      "Epoch 513/9999\n",
      "----------\n",
      "epoch time: 1.4361145496368408   total time: 612.8741836547852\n",
      "Epoch 514/9999\n",
      "----------\n",
      "epoch time: 1.598923921585083   total time: 614.4732322692871\n",
      "Epoch 515/9999\n",
      "----------\n",
      "epoch time: 1.6213998794555664   total time: 616.0951519012451\n",
      "Epoch 516/9999\n",
      "----------\n",
      "epoch time: 1.7887918949127197   total time: 617.8842828273773\n",
      "Epoch 517/9999\n",
      "----------\n",
      "epoch time: 1.591355800628662   total time: 619.4758057594299\n",
      "Epoch 518/9999\n",
      "----------\n",
      "epoch time: 1.6422228813171387   total time: 621.118497133255\n",
      "Epoch 519/9999\n",
      "----------\n",
      "epoch time: 1.6940109729766846   total time: 622.8131995201111\n",
      "Epoch 520/9999\n",
      "----------\n",
      "loss= 0.5705218792228955 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 2.1581690311431885   total time: 624.9714770317078\n",
      "Epoch 521/9999\n",
      "----------\n",
      "epoch time: 1.3887381553649902   total time: 626.3604652881622\n",
      "Epoch 522/9999\n",
      "----------\n",
      "epoch time: 1.3317840099334717   total time: 627.6925735473633\n",
      "Epoch 523/9999\n",
      "----------\n",
      "epoch time: 1.3690404891967773   total time: 629.0617282390594\n",
      "Epoch 524/9999\n",
      "----------\n",
      "epoch time: 1.3692166805267334   total time: 630.4314866065979\n",
      "Epoch 525/9999\n",
      "----------\n",
      "epoch time: 1.3767707347869873   total time: 631.8083989620209\n",
      "Epoch 526/9999\n",
      "----------\n",
      "epoch time: 1.4097087383270264   total time: 633.2182374000549\n",
      "Epoch 527/9999\n",
      "----------\n",
      "epoch time: 0.729248046875   total time: 633.9478054046631\n",
      "Epoch 528/9999\n",
      "----------\n",
      "epoch time: 0.4691355228424072   total time: 634.4171481132507\n",
      "Epoch 529/9999\n",
      "----------\n",
      "epoch time: 0.4786996841430664   total time: 634.8961663246155\n",
      "Epoch 530/9999\n",
      "----------\n",
      "loss= 0.5711165660566279 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 0.7866215705871582   total time: 635.6831035614014\n",
      "Epoch 531/9999\n",
      "----------\n",
      "epoch time: 0.4807569980621338   total time: 636.1639170646667\n",
      "Epoch 532/9999\n",
      "----------\n",
      "epoch time: 0.4934413433074951   total time: 636.6576981544495\n",
      "Epoch 533/9999\n",
      "----------\n",
      "epoch time: 0.4691896438598633   total time: 637.1270277500153\n",
      "Epoch 534/9999\n",
      "----------\n",
      "epoch time: 0.5106394290924072   total time: 637.6377828121185\n",
      "Epoch 535/9999\n",
      "----------\n",
      "epoch time: 0.5209589004516602   total time: 638.1595726013184\n",
      "Epoch 536/9999\n",
      "----------\n",
      "epoch time: 0.47489285469055176   total time: 638.6348204612732\n",
      "Epoch 537/9999\n",
      "----------\n",
      "epoch time: 0.47836804389953613   total time: 639.1133210659027\n",
      "Epoch 538/9999\n",
      "----------\n",
      "epoch time: 0.49085187911987305   total time: 639.604305267334\n",
      "Epoch 539/9999\n",
      "----------\n",
      "epoch time: 0.4798922538757324   total time: 640.0844266414642\n",
      "Epoch 540/9999\n",
      "----------\n",
      "loss= 0.57294406518006 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 0.763420581817627   total time: 640.8481647968292\n",
      "Epoch 541/9999\n",
      "----------\n",
      "epoch time: 0.4923057556152344   total time: 641.3407349586487\n",
      "Epoch 542/9999\n",
      "----------\n",
      "epoch time: 0.5807552337646484   total time: 641.9216330051422\n",
      "Epoch 543/9999\n",
      "----------\n",
      "epoch time: 0.5458359718322754   total time: 642.4677469730377\n",
      "Epoch 544/9999\n",
      "----------\n",
      "epoch time: 1.1930291652679443   total time: 643.6609642505646\n",
      "Epoch 545/9999\n",
      "----------\n",
      "epoch time: 1.4093451499938965   total time: 645.0706813335419\n",
      "Epoch 546/9999\n",
      "----------\n",
      "epoch time: 1.4443914890289307   total time: 646.515222787857\n",
      "Epoch 547/9999\n",
      "----------\n",
      "epoch time: 1.3715972900390625   total time: 647.8870475292206\n",
      "Epoch 548/9999\n",
      "----------\n",
      "epoch time: 1.4607226848602295   total time: 649.3479073047638\n",
      "Epoch 549/9999\n",
      "----------\n",
      "epoch time: 1.3727426528930664   total time: 650.7207601070404\n",
      "Epoch 550/9999\n",
      "----------\n",
      "loss= 0.5705859272870247 acc= 0.7443946188340808 acctrain= 0.7078651685393258\n",
      "epoch time: 2.704500198364258   total time: 653.4253721237183\n",
      "Epoch 551/9999\n",
      "----------\n",
      "epoch time: 1.2204101085662842   total time: 654.6462867259979\n",
      "Epoch 552/9999\n",
      "----------\n",
      "epoch time: 1.4596996307373047   total time: 656.1070609092712\n",
      "Epoch 553/9999\n",
      "----------\n",
      "epoch time: 1.4362380504608154   total time: 657.5434482097626\n",
      "Epoch 554/9999\n",
      "----------\n",
      "epoch time: 1.4828541278839111   total time: 659.0266194343567\n",
      "Epoch 555/9999\n",
      "----------\n",
      "epoch time: 1.3893094062805176   total time: 660.4162409305573\n",
      "Epoch 556/9999\n",
      "----------\n",
      "epoch time: 1.3103747367858887   total time: 661.7268288135529\n",
      "Epoch 557/9999\n",
      "----------\n",
      "epoch time: 1.3908579349517822   total time: 663.1178300380707\n",
      "Epoch 558/9999\n",
      "----------\n",
      "epoch time: 1.6855709552764893   total time: 664.8036923408508\n",
      "Epoch 559/9999\n",
      "----------\n",
      "epoch time: 1.8013854026794434   total time: 666.6053235530853\n",
      "Epoch 560/9999\n",
      "----------\n",
      "loss= 0.5704421038852144 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 2.766878604888916   total time: 669.3723759651184\n",
      "Epoch 561/9999\n",
      "----------\n",
      "epoch time: 1.5934669971466064   total time: 670.9659283161163\n",
      "Epoch 562/9999\n",
      "----------\n",
      "epoch time: 1.6968319416046143   total time: 672.6629004478455\n",
      "Epoch 563/9999\n",
      "----------\n",
      "epoch time: 1.5308527946472168   total time: 674.1944665908813\n",
      "Epoch 564/9999\n",
      "----------\n",
      "epoch time: 1.3838653564453125   total time: 675.5785338878632\n",
      "Epoch 565/9999\n",
      "----------\n",
      "epoch time: 1.4370310306549072   total time: 677.015695810318\n",
      "Epoch 566/9999\n",
      "----------\n",
      "epoch time: 1.3273870944976807   total time: 678.34321641922\n",
      "Epoch 567/9999\n",
      "----------\n",
      "epoch time: 1.3682126998901367   total time: 679.7119705677032\n",
      "Epoch 568/9999\n",
      "----------\n",
      "epoch time: 1.3579120635986328   total time: 681.0700073242188\n",
      "Epoch 569/9999\n",
      "----------\n",
      "epoch time: 1.3666813373565674   total time: 682.4370250701904\n",
      "Epoch 570/9999\n",
      "----------\n",
      "loss= 0.5707085317025805 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 1.4016704559326172   total time: 683.8392810821533\n",
      "Epoch 571/9999\n",
      "----------\n",
      "epoch time: 0.4649505615234375   total time: 684.3055031299591\n",
      "Epoch 572/9999\n",
      "----------\n",
      "epoch time: 0.4683849811553955   total time: 684.7740647792816\n",
      "Epoch 573/9999\n",
      "----------\n",
      "epoch time: 0.4904286861419678   total time: 685.265052318573\n",
      "Epoch 574/9999\n",
      "----------\n",
      "epoch time: 0.4604334831237793   total time: 685.7258007526398\n",
      "Epoch 575/9999\n",
      "----------\n",
      "epoch time: 0.48628973960876465   total time: 686.2126500606537\n",
      "Epoch 576/9999\n",
      "----------\n",
      "epoch time: 0.5617334842681885   total time: 686.7745137214661\n",
      "Epoch 577/9999\n",
      "----------\n",
      "epoch time: 0.554267406463623   total time: 687.3289070129395\n",
      "Epoch 578/9999\n",
      "----------\n",
      "epoch time: 0.4857656955718994   total time: 687.8149094581604\n",
      "Epoch 579/9999\n",
      "----------\n",
      "epoch time: 0.47905945777893066   total time: 688.2940843105316\n",
      "Epoch 580/9999\n",
      "----------\n",
      "loss= 0.5700544360106301 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 0.7925043106079102   total time: 689.0867035388947\n",
      "Epoch 581/9999\n",
      "----------\n",
      "epoch time: 0.9190926551818848   total time: 690.0059053897858\n",
      "Epoch 582/9999\n",
      "----------\n",
      "epoch time: 1.4568390846252441   total time: 691.4631686210632\n",
      "Epoch 583/9999\n",
      "----------\n",
      "epoch time: 1.4607901573181152   total time: 692.924204826355\n",
      "Epoch 584/9999\n",
      "----------\n",
      "epoch time: 1.3575830459594727   total time: 694.2820599079132\n",
      "Epoch 585/9999\n",
      "----------\n",
      "epoch time: 1.4250824451446533   total time: 695.7073850631714\n",
      "Epoch 586/9999\n",
      "----------\n",
      "epoch time: 1.4049232006072998   total time: 697.1125335693359\n",
      "Epoch 587/9999\n",
      "----------\n",
      "epoch time: 1.4006221294403076   total time: 698.5137021541595\n",
      "Epoch 588/9999\n",
      "----------\n",
      "epoch time: 1.4831666946411133   total time: 699.997397184372\n",
      "Epoch 589/9999\n",
      "----------\n",
      "epoch time: 1.549572229385376   total time: 701.54723072052\n",
      "Epoch 590/9999\n",
      "----------\n",
      "loss= 0.5703405495983602 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 2.417168140411377   total time: 703.9649000167847\n",
      "Epoch 591/9999\n",
      "----------\n",
      "epoch time: 1.380533218383789   total time: 705.3455092906952\n",
      "Epoch 592/9999\n",
      "----------\n",
      "epoch time: 1.353149652481079   total time: 706.6988346576691\n",
      "Epoch 593/9999\n",
      "----------\n",
      "epoch time: 1.3489246368408203   total time: 708.0479125976562\n",
      "Epoch 594/9999\n",
      "----------\n",
      "epoch time: 1.4450504779815674   total time: 709.4932065010071\n",
      "Epoch 595/9999\n",
      "----------\n",
      "epoch time: 1.821031093597412   total time: 711.3145909309387\n",
      "Epoch 596/9999\n",
      "----------\n",
      "epoch time: 1.7458369731903076   total time: 713.0607414245605\n",
      "Epoch 597/9999\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time: 1.7450461387634277   total time: 714.806617975235\n",
      "Epoch 598/9999\n",
      "----------\n",
      "epoch time: 1.7863690853118896   total time: 716.593184709549\n",
      "Epoch 599/9999\n",
      "----------\n",
      "epoch time: 1.6598224639892578   total time: 718.2534866333008\n",
      "Epoch 600/9999\n",
      "----------\n",
      "loss= 0.570543733145624 acc= 0.7443946188340808 acctrain= 0.7056179775280899\n",
      "epoch time: 2.1872315406799316   total time: 720.4408886432648\n",
      "Epoch 601/9999\n",
      "----------\n",
      "epoch time: 1.3735592365264893   total time: 721.8147733211517\n",
      "Epoch 602/9999\n",
      "----------\n",
      "epoch time: 1.3600847721099854   total time: 723.1750311851501\n",
      "Epoch 603/9999\n",
      "----------\n",
      "epoch time: 1.408259391784668   total time: 724.5834038257599\n",
      "Epoch 604/9999\n",
      "----------\n",
      "epoch time: 1.393547534942627   total time: 725.9770638942719\n",
      "Epoch 605/9999\n",
      "----------\n",
      "epoch time: 1.361781358718872   total time: 727.338968038559\n",
      "Epoch 606/9999\n",
      "----------\n",
      "epoch time: 1.400041103363037   total time: 728.7391719818115\n",
      "Epoch 607/9999\n",
      "----------\n",
      "epoch time: 0.5519504547119141   total time: 729.2913138866425\n",
      "Epoch 608/9999\n",
      "----------\n",
      "epoch time: 0.5086133480072021   total time: 729.8002812862396\n",
      "Epoch 609/9999\n",
      "----------\n",
      "epoch time: 0.48505306243896484   total time: 730.2855958938599\n",
      "Epoch 610/9999\n",
      "----------\n",
      "loss= 0.570782972959125 acc= 0.7443946188340808 acctrain= 0.7056179775280899\n",
      "epoch time: 0.7780706882476807   total time: 731.0638279914856\n",
      "Epoch 611/9999\n",
      "----------\n",
      "epoch time: 0.5087294578552246   total time: 731.5731749534607\n",
      "Epoch 612/9999\n",
      "----------\n",
      "epoch time: 0.51548171043396   total time: 732.0888047218323\n",
      "Epoch 613/9999\n",
      "----------\n",
      "epoch time: 0.4820539951324463   total time: 732.5709879398346\n",
      "Epoch 614/9999\n",
      "----------\n",
      "epoch time: 0.4676027297973633   total time: 733.0387251377106\n",
      "Epoch 615/9999\n",
      "----------\n",
      "epoch time: 0.5646374225616455   total time: 733.6035182476044\n",
      "Epoch 616/9999\n",
      "----------\n",
      "epoch time: 0.49086642265319824   total time: 734.0945272445679\n",
      "Epoch 617/9999\n",
      "----------\n",
      "epoch time: 0.46242380142211914   total time: 734.5574021339417\n",
      "Epoch 618/9999\n",
      "----------\n",
      "epoch time: 0.46846485137939453   total time: 735.0259833335876\n",
      "Epoch 619/9999\n",
      "----------\n",
      "epoch time: 0.4885694980621338   total time: 735.5146980285645\n",
      "Epoch 620/9999\n",
      "----------\n",
      "loss= 0.5700844425390654 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 1.6938180923461914   total time: 737.2086644172668\n",
      "Epoch 621/9999\n",
      "----------\n",
      "epoch time: 1.4281408786773682   total time: 738.636866569519\n",
      "Epoch 622/9999\n",
      "----------\n",
      "epoch time: 1.311903715133667   total time: 739.9493515491486\n",
      "Epoch 623/9999\n",
      "----------\n",
      "epoch time: 1.3829410076141357   total time: 741.3324484825134\n",
      "Epoch 624/9999\n",
      "----------\n",
      "epoch time: 1.5278022289276123   total time: 742.8605852127075\n",
      "Epoch 625/9999\n",
      "----------\n",
      "epoch time: 1.4711313247680664   total time: 744.3321104049683\n",
      "Epoch 626/9999\n",
      "----------\n",
      "epoch time: 1.889782190322876   total time: 746.2220442295074\n",
      "Epoch 627/9999\n",
      "----------\n",
      "epoch time: 1.5268375873565674   total time: 747.7491261959076\n",
      "Epoch 628/9999\n",
      "----------\n",
      "epoch time: 1.363182544708252   total time: 749.1126503944397\n",
      "Epoch 629/9999\n",
      "----------\n",
      "epoch time: 1.4320347309112549   total time: 750.5448961257935\n",
      "Epoch 630/9999\n",
      "----------\n",
      "loss= 0.5699133125254926 acc= 0.7443946188340808 acctrain= 0.7056179775280899\n",
      "epoch time: 2.164942502975464   total time: 752.7104201316833\n",
      "Epoch 631/9999\n",
      "----------\n",
      "epoch time: 1.2195112705230713   total time: 753.930410861969\n",
      "Epoch 632/9999\n",
      "----------\n",
      "epoch time: 1.343034267425537   total time: 755.2737317085266\n",
      "Epoch 633/9999\n",
      "----------\n",
      "epoch time: 1.539675235748291   total time: 756.813756942749\n",
      "Epoch 634/9999\n",
      "----------\n",
      "epoch time: 1.6696619987487793   total time: 758.4835517406464\n",
      "Epoch 635/9999\n",
      "----------\n",
      "epoch time: 1.5426945686340332   total time: 760.0264873504639\n",
      "Epoch 636/9999\n",
      "----------\n",
      "epoch time: 1.686631202697754   total time: 761.7135851383209\n",
      "Epoch 637/9999\n",
      "----------\n",
      "epoch time: 1.5758683681488037   total time: 763.2895896434784\n",
      "Epoch 638/9999\n",
      "----------\n",
      "epoch time: 1.7288153171539307   total time: 765.0186095237732\n",
      "Epoch 639/9999\n",
      "----------\n",
      "epoch time: 1.786703109741211   total time: 766.8055760860443\n",
      "Epoch 640/9999\n",
      "----------\n",
      "loss= 0.5696316999571206 acc= 0.7443946188340808 acctrain= 0.7056179775280899\n",
      "epoch time: 2.006316900253296   total time: 768.8120195865631\n",
      "Epoch 641/9999\n",
      "----------\n",
      "epoch time: 1.4189553260803223   total time: 770.2322371006012\n",
      "Epoch 642/9999\n",
      "----------\n",
      "epoch time: 1.4392719268798828   total time: 771.6716976165771\n",
      "Epoch 643/9999\n",
      "----------\n",
      "epoch time: 1.5601670742034912   total time: 773.2322926521301\n",
      "Epoch 644/9999\n",
      "----------\n",
      "epoch time: 1.4878606796264648   total time: 774.7210357189178\n",
      "Epoch 645/9999\n",
      "----------\n",
      "epoch time: 1.3913500308990479   total time: 776.1127696037292\n",
      "Epoch 646/9999\n",
      "----------\n",
      "epoch time: 1.4029936790466309   total time: 777.516036272049\n",
      "Epoch 647/9999\n",
      "----------\n",
      "epoch time: 0.7521383762359619   total time: 778.2695620059967\n",
      "Epoch 648/9999\n",
      "----------\n",
      "epoch time: 0.6355745792388916   total time: 778.9057400226593\n",
      "Epoch 649/9999\n",
      "----------\n",
      "epoch time: 0.6787006855010986   total time: 779.584778547287\n",
      "Epoch 650/9999\n",
      "----------\n",
      "loss= 0.5707450300588736 acc= 0.7443946188340808 acctrain= 0.7067415730337079\n",
      "epoch time: 0.6977174282073975   total time: 780.2826480865479\n",
      "Epoch 651/9999\n",
      "----------\n",
      "epoch time: 0.6492316722869873   total time: 780.9319417476654\n",
      "Epoch 652/9999\n",
      "----------\n",
      "epoch time: 0.6508314609527588   total time: 781.5829155445099\n",
      "Epoch 653/9999\n",
      "----------\n",
      "epoch time: 0.5647313594818115   total time: 782.1479148864746\n",
      "Epoch 654/9999\n",
      "----------\n",
      "epoch time: 0.6754598617553711   total time: 782.8235471248627\n",
      "Epoch 655/9999\n",
      "----------\n",
      "epoch time: 0.5412027835845947   total time: 783.365424156189\n",
      "Epoch 656/9999\n",
      "----------\n",
      "epoch time: 0.5435166358947754   total time: 783.9091362953186\n",
      "Epoch 657/9999\n",
      "----------\n",
      "epoch time: 0.5087766647338867   total time: 784.4180517196655\n",
      "Epoch 658/9999\n",
      "----------\n",
      "epoch time: 0.6944422721862793   total time: 785.1126267910004\n",
      "Epoch 659/9999\n",
      "----------\n",
      "epoch time: 1.0872166156768799   total time: 786.2000091075897\n",
      "Epoch 660/9999\n",
      "----------\n",
      "loss= 0.5700706739329436 acc= 0.7443946188340808 acctrain= 0.7056179775280899\n",
      "epoch time: 2.244147777557373   total time: 788.4452257156372\n",
      "Epoch 661/9999\n",
      "----------\n",
      "epoch time: 1.5176174640655518   total time: 789.9629681110382\n",
      "Epoch 662/9999\n",
      "----------\n",
      "epoch time: 1.4673466682434082   total time: 791.4307355880737\n",
      "Epoch 663/9999\n",
      "----------\n",
      "epoch time: 1.3452508449554443   total time: 792.7770373821259\n",
      "Epoch 664/9999\n",
      "----------\n",
      "epoch time: 1.3773343563079834   total time: 794.154648065567\n",
      "Epoch 665/9999\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13258/1903703518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#         acc = valid2(test_loader,model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0macctrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13258/2415629650.py\u001b[0m in \u001b[0;36mvalid2\u001b[0;34m(test_loader, model)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mtarget_var\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m#         print(scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GSTdataset_train = GST_coef_dataset(GSTcoe_all, label_all, 'train')\n",
    "GSTdataset_test = GST_coef_dataset(GSTcoe_all, label_all, 'test')\n",
    "train_loader = torch.utils.data.DataLoader(GSTdataset_train, batch_size=4,\n",
    "               shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(GSTdataset_test, batch_size=4,\n",
    "               shuffle=False, pin_memory=True)\n",
    "model = MLPs(nodeNum = num_coe)\n",
    "model = nn.DataParallel(model, device_ids = [i for i in range(torch.cuda.device_count())])\n",
    "model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(100), gamma=0.3)\n",
    "\n",
    "st = time.time()\n",
    "#------------------------------------- 训练阶段-----------------------------------------------\n",
    "for epoch in range(1000):\n",
    "    st_epoch = time.time()\n",
    "    print('Epoch {}/{}'.format(epoch, args.epochs - 1))\n",
    "    print('-' * 10)\n",
    "    bar = Bar('>>>', fill='>', max=len(train_loader))\n",
    "    loss_train = []\n",
    "    \n",
    "    acc = valid2(test_loader,model)\n",
    "#         acc = valid2(test_loader,model)\n",
    "    acctrain = valid2(train_loader,model)\n",
    "#     print(\"loss=\", np.mean(loss_train),\"acc=\", acc,\"acctrain=\", acctrain) #loss.detach().cpu().numpy()\n",
    "    \n",
    "    for i, (input, target) in (enumerate(train_loader)):\n",
    "\n",
    "\n",
    "        input_var = input.to(device).float()\n",
    "        target_var =target.to(device).long()\n",
    "\n",
    "\n",
    "        # 前向传播\n",
    "#         scores = model(input_var).squeeze(1).squeeze(1)\n",
    "        scores = model(input_var)\n",
    "        scores = np.squeeze(scores)\n",
    "        \n",
    "#         print(scores)\n",
    "#         print(np.shape(scores))\n",
    "#         print(target_var)\n",
    "#         print(np.shape(target_var))\n",
    "\n",
    "        loss = criteria(scores, target_var)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train.append(loss.item())\n",
    "        bar.next()\n",
    "        \n",
    "    bar.finish()\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        # 计算分类的准确率\n",
    "        acc = valid2(test_loader,model)\n",
    "        acctrain = valid2(train_loader,model)\n",
    "        \n",
    "        print(\"loss=\", np.mean(loss_train),\"acc=\", acc,\"acctrain=\", acctrain) #loss.detach().cpu().numpy()\n",
    "#         break\n",
    "\n",
    "    bt_epoch = time.time()\n",
    "    print('epoch time:',bt_epoch-st_epoch,'  total time:', bt_epoch - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30  36  42]\n",
      " [ 66  81  96]\n",
      " [102 126 150]]\n",
      "[[ 30  36  42]\n",
      " [ 66  81  96]\n",
      " [102 126 150]]\n",
      "[[ 30  36  42]\n",
      " [ 66  81  96]\n",
      " [102 126 150]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(np.dot(A,A))\n",
    "print(A@A)\n",
    "print(np.matmul(A,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lazy_diffusion(A):\n",
    "    ## input adjacency matrix\n",
    "    Ad = A\n",
    "    N = np.shape(Ad)[0]\n",
    "    one = np.ones((N,1))\n",
    "    d = np.power((np.dot(Ad,one)).squeeze(),-1/2)\n",
    "\n",
    "    D_sq = np.diag(d.squeeze())\n",
    "\n",
    "    \n",
    "    Ad = np.matmul(D_sq,Ad)\n",
    "    Ad = np.matmul(Ad,D_sq)\n",
    "    \n",
    "    I = np.identity(N)\n",
    "    T = 0.5*(Ad + I)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphScatteringTransform:\n",
    "    \"\"\"\n",
    "    graphScatteringTransform: base class for the computation of the graph\n",
    "        scattering transform coefficients\n",
    "\n",
    "    Initialization:\n",
    "\n",
    "    Input:\n",
    "        numScales (int): number of wavelet scales (size of the filter bank)\n",
    "        numLayers (int): number of layers\n",
    "        adjacencyMatrix (np.array): of shape N x N\n",
    "\n",
    "    Output:\n",
    "        Creates graph scattering transform base handler\n",
    "\n",
    "    Methods:\n",
    "\n",
    "        Phi = .computeTransform(x): computes the graph scattering coefficients\n",
    "            of input x (where x is a np.array of shape B x F x N, with B the\n",
    "            batch size, F the number of node features, and N the number of\n",
    "            nodes)\n",
    "    \"\"\"\n",
    "\n",
    "    # We use this as base class to then specify the wavelet and the self.U\n",
    "    # All of them use np.abs() as noinlinearity. I could make this generic\n",
    "    # afterward as well, but not for now.\n",
    "\n",
    "    def __init__(self, numScales, numLayers, adjacencyMatrix):\n",
    "\n",
    "        self.J = numScales\n",
    "        self.L = numLayers\n",
    "        self.W = adjacencyMatrix.copy()\n",
    "        self.N = self.W.shape[0]\n",
    "        assert self.W.shape[1] == self.N\n",
    "        self.U = None\n",
    "        self.H = None\n",
    "\n",
    "    def computeTransform(self, x):\n",
    "        # Check the dimension of x: batchSize x numberFeatures x numberNodes\n",
    "        assert len(x.shape) == 3\n",
    "        B = x.shape[0] # batchSize\n",
    "        F = x.shape[1] # numberFeatures\n",
    "        assert x.shape[2] == self.N\n",
    "        # Start creating the output\n",
    "        #   Add the dimensions for B and F in low-pass operator U\n",
    "        U = self.U.reshape([1, self.N, 1]) # 1 x N x 1\n",
    "        #   Compute the first coefficient\n",
    "        Phi = x @ U # B x F x 1\n",
    "        rhoHx = x.reshape(B, 1, F, self.N) # B x 1 x F x N\n",
    "        # Reshape U once again, because from now on, it will have to multiply\n",
    "        # J elements (we want it to be 1 x J x N x 1)\n",
    "        U = U.reshape(1, 1, self.N, 1) # 1 x 1 x N x 1\n",
    "        U = np.tile(U, [1, self.J, 1, 1])\n",
    "        # Now, we move to the rest of the layers\n",
    "        for l in range(1,self.L): # l = 1,2,...,L\n",
    "            nextRhoHx = np.empty([B, 0, F, self.N])\n",
    "            for j in range(self.J ** (l-1)): # j = 0,...,l-1\n",
    "                thisX = rhoHx[:,j,:,:] # B x J x F x N\n",
    "                thisHx = thisX.reshape(B, 1, F, self.N) \\\n",
    "                            @ self.H.reshape(1, self.J, self.N, self.N)\n",
    "                    # B x J x F x N\n",
    "                thisRhoHx = np.abs(thisHx) # B x J x F x N\n",
    "                nextRhoHx = np.concatenate((nextRhoHx, thisRhoHx), axis = 1)\n",
    "\n",
    "                phi_j = thisRhoHx @ U # B x J x F x 1\n",
    "                phi_j = phi_j.squeeze(3) # B x J x F\n",
    "                phi_j = phi_j.transpose(0, 2, 1) # B x F x J\n",
    "                Phi = np.concatenate((Phi, phi_j), axis = 2) # Keeps adding the\n",
    "                    # coefficients\n",
    "            rhoHx = nextRhoHx.copy()\n",
    "\n",
    "        return Phi\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroTolerance = 1e-6\n",
    "class stochastic_DiffusionScattering(GraphScatteringTransform):\n",
    "    \"\"\"\n",
    "    DiffusionScattering: diffusion scattering transform\n",
    "\n",
    "    Initialization:\n",
    "\n",
    "    Input:\n",
    "        numScales (int): number of wavelet scales (size of the filter bank)\n",
    "        numLayers (int): number of layers\n",
    "        adjacencyMatrix (np.array): of shape N x N\n",
    "\n",
    "    Output:\n",
    "        Instantiates the class for the diffusion scattering transform\n",
    "\n",
    "    Methods:\n",
    "\n",
    "        Phi = .computeTransform(x): computes the diffusion scattering\n",
    "            coefficients of input x (np.array of shape B x F x N, with B the\n",
    "            batch size, F the number of node features, and N the number of\n",
    "            nodes)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numScales, numLayers, adjacencyMatrix):\n",
    "        super().__init__(numScales, numLayers, adjacencyMatrix)\n",
    "        d = np.sum(self.W, axis = 1)\n",
    "        killIndices = np.nonzero(d < zeroTolerance)[0] # Nodes with zero\n",
    "            # degree or negative degree (there shouldn't be any since (i) the\n",
    "            # graph is connected -all nonzero degrees- and (ii) all edge\n",
    "            # weights are supposed to be positive)\n",
    "        dReady = d.copy()\n",
    "        dReady[killIndices] = 1.\n",
    "        # Apply sqrt and invert without fear of getting nans or stuff\n",
    "        dSqrtInv = 1./np.sqrt(dReady)\n",
    "        # Put back zeros in those numbers that had been failing\n",
    "        dSqrtInv[killIndices] = 0.\n",
    "        # Inverse diagonal squareroot matrix\n",
    "        DsqrtInv = np.diag(dSqrtInv)\n",
    "        # Normalized adjacency\n",
    "        A = DsqrtInv.dot(self.W.dot(DsqrtInv))\n",
    "        # Lazy diffusion\n",
    "        self.T = 1/2*(np.eye(self.N) + A)\n",
    "        # Low-pass average operator\n",
    "        self.U = d/np.linalg.norm(d, 1)\n",
    "        # Construct wavelets\n",
    "        self.H = stochastic_diffusionWavelets(self.J, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_diffusionWavelets(J, W):\n",
    "    \"\"\"\n",
    "    diffusionWavelets: computes the filter bank for the diffusion wavelets\n",
    "\n",
    "    See R. R. Coifman and M. Maggioni, “Diffusion wavelets,” Appl. Comput.\n",
    "        Harmonic Anal., vol. 21, no. 1, pp. 53–94, July 2006.\n",
    "    Alternatively, see eq. (6) of F. Gama, A. Ribeiro, and J. Bruna, “Diffusion\n",
    "        Scattering Transforms on Graphs,” in 7th Int. Conf. Learning\n",
    "        Representations. New Orleans, LA: Assoc. Comput. Linguistics,\n",
    "        6-9 May 2019, pp. 1–12.\n",
    "\n",
    "    Input:\n",
    "        J (int): number of scales\n",
    "        T (np.array): lazy diffusion operator\n",
    "\n",
    "    Output:\n",
    "        H (np.array): of shape J x N x N contains the J matrices corresponding\n",
    "            to all the filter scales\n",
    "    \"\"\"\n",
    "    # J is the number of scales, and we do waveletgs from 0 to J-1, so it always\n",
    "    # needs to be at least 1: I need at last one scale\n",
    "    \n",
    "    \n",
    "    assert J > 0\n",
    "    N = W.shape[0] # Number of nodes\n",
    "    T_s = np.zeros((2 ** (J-1),N,N))\n",
    "    for i in range(2*J-4):\n",
    "        W_s = graph_stochastic_sampling(W,p=0.95)\n",
    "        T_s[i] = compute_lazy_diffusion(W_s)\n",
    "    assert W.shape[1] == N # Check it's a square matrix\n",
    "    I = np.eye(N) # Identity matrix\n",
    "    H = (I - T_s[0]).reshape(1, N, N) # 1 x N x N\n",
    "    for j in range(1,J):\n",
    "        thisPower = 2 ** (j-1) # 2^(j-1)\n",
    "        powerT1 = I\n",
    "        for k in range(thisPower):\n",
    "            powerT1 = T_s[k] @ powerT1\n",
    "        powerT2 = I\n",
    "        for k in range(thisPower):\n",
    "            powerT2 = T_s[k] @ powerT2\n",
    "        \n",
    "        thisH = powerT1 @ (I - powerT2) # T^{2^{j-1}} * (I - T^{2^{j-1}})\n",
    "        H = np.concatenate((H, thisH.reshape(1, N, N)), axis=0)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusionWavelets(J, T):\n",
    "    \"\"\"\n",
    "    diffusionWavelets: computes the filter bank for the diffusion wavelets\n",
    "\n",
    "    See R. R. Coifman and M. Maggioni, “Diffusion wavelets,” Appl. Comput.\n",
    "        Harmonic Anal., vol. 21, no. 1, pp. 53–94, July 2006.\n",
    "    Alternatively, see eq. (6) of F. Gama, A. Ribeiro, and J. Bruna, “Diffusion\n",
    "        Scattering Transforms on Graphs,” in 7th Int. Conf. Learning\n",
    "        Representations. New Orleans, LA: Assoc. Comput. Linguistics,\n",
    "        6-9 May 2019, pp. 1–12.\n",
    "\n",
    "    Input:\n",
    "        J (int): number of scales\n",
    "        T (np.array): lazy diffusion operator\n",
    "\n",
    "    Output:\n",
    "        H (np.array): of shape J x N x N contains the J matrices corresponding\n",
    "            to all the filter scales\n",
    "    \"\"\"\n",
    "    # J is the number of scales, and we do waveletgs from 0 to J-1, so it always\n",
    "    # needs to be at least 1: I need at last one scale\n",
    "    assert J > 0\n",
    "    N = T.shape[0] # Number of nodes\n",
    "    assert T.shape[1] == N # Check it's a square matrix\n",
    "    I = np.eye(N) # Identity matrix\n",
    "    H = (I - T).reshape(1, N, N) # 1 x N x N\n",
    "    for j in range(1,J):\n",
    "        thisPower = 2 ** (j-1) # 2^(j-1)\n",
    "        powerT = np.linalg.matrix_power(T, thisPower) # T^{2^{j-1}}\n",
    "        thisH = powerT @ (I - powerT) # T^{2^{j-1}} * (I - T^{2^{j-1}})\n",
    "        H = np.concatenate((H, thisH.reshape(1, N, N)), axis=0)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def graph_stochastic_sampling(A,p):\n",
    "    # input adjacency matrix:A\n",
    "    N = np.shape(A)[0]\n",
    "    rdmx = np.random.rand(N,N)\n",
    "#     print(rdmx)\n",
    "    rdmx = (rdmx<p)\n",
    "#     print(rdmx)\n",
    "    sampled_A = A * rdmx\n",
    "#     print(sampled_A)\n",
    "    return sampled_A\n",
    "    \n",
    "graph_stochastic_sampling(A,p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "[[[ 4.16666667e-01 -1.05409255e-01 -1.25000000e-01]\n",
      "  [-2.10818511e-01  3.33333333e-01 -1.58113883e-01]\n",
      "  [-2.91666667e-01 -2.10818511e-01  3.12500000e-01]]\n",
      "\n",
      " [[ 1.84375000e-01 -5.27046277e-02 -5.05208333e-02]\n",
      "  [-9.88211769e-02  1.66666667e-01 -8.23509807e-02]\n",
      "  [-1.23437500e-01 -1.05409255e-01  1.45052083e-01]]\n",
      "\n",
      " [[ 1.17972819e-01 -3.95284708e-02 -2.77364095e-02]\n",
      "  [-6.85314568e-02  1.25000000e-01 -6.45554485e-02]\n",
      "  [-7.35941569e-02 -7.90569415e-02  9.92970785e-02]]\n",
      "\n",
      " [[ 2.79585461e-02 -1.23526471e-02 -4.21364807e-03]\n",
      "  [-1.89665635e-02  3.90625000e-02 -2.13983360e-02]\n",
      "  [-1.46711681e-02 -2.47052942e-02  2.68668341e-02]]\n",
      "\n",
      " [[ 1.17287134e-03 -8.20292972e-04  6.20628632e-05]\n",
      "  [-1.07148009e-03  2.59399414e-03 -1.51499238e-03]\n",
      "  [-3.35098845e-04 -1.64058594e-03  1.46454649e-03]]]\n"
     ]
    }
   ],
   "source": [
    "T = compute_lazy_diffusion(A)\n",
    "# print(type(T))\n",
    "H = diffusionWavelets(5, T)\n",
    "print(np.shape(H))\n",
    "print(type(H))\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756a0a4d35cf40bc89cc05877f043d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(781,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929902de488841cab375867813d2c39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08001544750009781\n"
     ]
    }
   ],
   "source": [
    "label_all = np.zeros(len(data))\n",
    "times = 2000\n",
    "for k,(g, labels) in (enumerate(data)):\n",
    "    \n",
    "    for j in tqdm(range(times)):\n",
    "        A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "        \n",
    "\n",
    "        for i in range(g.num_edges()):\n",
    "            A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "        A = graph_stochastic_sampling(A,p=0.95)\n",
    "        GSTmodel = np_GST.DiffusionScattering(args.numScales, args.numLayers, A)\n",
    "        node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "        \n",
    "        co_GST = GSTmodel.computeTransform(node_attr)\n",
    "\n",
    "        if j == 0:\n",
    "            num_coe = np.shape(co_GST)[2]\n",
    "            GSTcoe_all = np.zeros((times,num_coe))\n",
    "\n",
    "        GSTcoe_all[j]=co_GST[0,0,:]\n",
    "\n",
    "    coe_mean = np.mean(GSTcoe_all,0)\n",
    "    print(coe_mean.shape)\n",
    "    if k == 0:\n",
    "        break\n",
    "\n",
    "times = 200\n",
    "for k,(g, labels) in (enumerate(data)):\n",
    "    \n",
    "    for j in tqdm(range(times)):\n",
    "        A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "        \n",
    "\n",
    "        for i in range(g.num_edges()):\n",
    "            A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "        A = graph_stochastic_sampling(A,p=0.95)\n",
    "        GSTmodel = np_GST.DiffusionScattering(args.numScales, args.numLayers, A)\n",
    "        node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "        \n",
    "        co_GST = GSTmodel.computeTransform(node_attr)\n",
    "\n",
    "        if j == 0:\n",
    "#             num_coe = np.shape(co_GST)[2]\n",
    "            bias_all = np.zeros(times)\n",
    "        \n",
    "        coe_bias = co_GST[0,0,:]-coe_mean\n",
    "        coe_bias_norm = pow(np.linalg.norm(coe_bias),2)\n",
    "        bias_all[j] = coe_bias_norm\n",
    "        var_coe = np.mean(bias_all)\n",
    "    print(var_coe)\n",
    "\n",
    "#         GSTcoe_all[j]=co_GST[0,0,:]-coe_mean\n",
    "\n",
    "#     coe_mean = np.mean(GSTcoe_all,0)\n",
    "#     print(coe_mean.shape)\n",
    "    if k == 0:\n",
    "        break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764e9123015e410c916583488e6eb144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.22222222e+00 2.35710676e+00 8.80430508e-01 7.94428338e-01\n",
      " 7.37835631e-01 0.00000000e+00 7.69548477e-01 3.21833862e-01\n",
      " 2.96864112e-01 2.75311278e-01 0.00000000e+00 3.11689708e-01\n",
      " 9.23092683e-02 7.82455411e-02 7.49288407e-02 0.00000000e+00\n",
      " 3.10750991e-01 9.36759319e-02 6.40815406e-02 5.69811085e-02\n",
      " 0.00000000e+00 2.11404950e-01 7.10295925e-02 4.67418390e-02\n",
      " 2.65350159e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.48185501e-01\n",
      " 9.58410847e-02 8.07310255e-02 6.00169164e-02 0.00000000e+00\n",
      " 1.62032958e-01 3.56073682e-02 3.34888357e-02 2.98655682e-02\n",
      " 0.00000000e+00 9.68804671e-02 3.09167884e-02 2.65597619e-02\n",
      " 2.33513916e-02 0.00000000e+00 6.36853991e-02 2.85865126e-02\n",
      " 2.23418303e-02 1.39930240e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.85956396e-02 4.75799648e-02 4.98658134e-02 4.48744417e-02\n",
      " 0.00000000e+00 4.49169127e-02 1.31164534e-02 1.27097648e-02\n",
      " 1.06949453e-02 0.00000000e+00 2.68930349e-02 8.84503997e-03\n",
      " 7.10174407e-03 5.88385008e-03 0.00000000e+00 1.47572680e-02\n",
      " 6.67356682e-03 4.97622050e-03 2.85878884e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.38312570e-02 2.93484854e-02 2.95432475e-02\n",
      " 3.34028406e-02 0.00000000e+00 2.60746762e-02 9.40677607e-03\n",
      " 8.87740137e-03 8.57117838e-03 0.00000000e+00 2.06956010e-02\n",
      " 8.26940051e-03 7.07257225e-03 6.68881564e-03 0.00000000e+00\n",
      " 1.40777652e-02 5.74049476e-03 4.00173603e-03 2.40203693e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.44710563e-02 1.75329286e-02\n",
      " 1.47287195e-02 1.49984281e-02 0.00000000e+00 2.47500315e-02\n",
      " 6.99402277e-03 4.53852536e-03 3.83322950e-03 0.00000000e+00\n",
      " 1.94893678e-02 5.65733779e-03 4.34853107e-03 3.02207130e-03\n",
      " 0.00000000e+00 9.24209419e-03 3.71512049e-03 3.60580871e-03\n",
      " 3.14067767e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.18315929e-02 4.10904896e-02 4.18453396e-02 3.15852510e-02\n",
      " 0.00000000e+00 3.53854856e-02 1.13825947e-02 9.31996503e-03\n",
      " 8.00206083e-03 0.00000000e+00 2.55769475e-02 8.43533994e-03\n",
      " 6.47073584e-03 5.31533600e-03 0.00000000e+00 1.50464450e-02\n",
      " 6.86192790e-03 5.71501570e-03 4.05864401e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 3.12433451e-02 1.55752678e-02 1.72619283e-02\n",
      " 1.52378097e-02 0.00000000e+00 1.41245610e-02 5.30092081e-03\n",
      " 3.94819101e-03 3.35406457e-03 0.00000000e+00 9.45842606e-03\n",
      " 3.90321138e-03 3.34166006e-03 3.05090075e-03 0.00000000e+00\n",
      " 9.60956280e-03 4.02580306e-03 3.44708899e-03 2.99949032e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.22390228e-02 1.27967350e-02\n",
      " 1.25686214e-02 1.22180936e-02 0.00000000e+00 9.66906400e-03\n",
      " 4.70019807e-03 4.56786484e-03 4.04714669e-03 0.00000000e+00\n",
      " 9.49844334e-03 3.82062969e-03 3.15519535e-03 2.52725309e-03\n",
      " 0.00000000e+00 6.72407994e-03 2.77882940e-03 2.02849573e-03\n",
      " 1.48571102e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.98253940e-02\n",
      " 6.16272516e-03 6.11902749e-03 5.76969621e-03 0.00000000e+00\n",
      " 9.82314942e-03 2.60320462e-03 2.61942016e-03 2.62879335e-03\n",
      " 0.00000000e+00 7.31028322e-03 1.93811202e-03 2.20029469e-03\n",
      " 2.31629543e-03 0.00000000e+00 3.73369000e-03 1.02828725e-03\n",
      " 9.82412278e-04 1.14871132e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.12558221e-02 1.17690401e-02 1.16069520e-02\n",
      " 1.03942807e-02 0.00000000e+00 1.35164598e-02 5.17409056e-03\n",
      " 5.10409289e-03 5.28414522e-03 0.00000000e+00 1.04990819e-02\n",
      " 4.73646725e-03 4.36362670e-03 4.16998316e-03 0.00000000e+00\n",
      " 1.04490330e-02 4.43283368e-03 3.40362699e-03 2.57500443e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.05386301e-02 5.66089677e-03\n",
      " 6.16824795e-03 5.71652993e-03 0.00000000e+00 5.66468229e-03\n",
      " 1.95534220e-03 1.64606950e-03 1.48973788e-03 0.00000000e+00\n",
      " 4.74260709e-03 1.73831575e-03 1.49032666e-03 1.24492637e-03\n",
      " 0.00000000e+00 4.18963649e-03 1.47863585e-03 1.11692698e-03\n",
      " 9.16619446e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.43014610e-03\n",
      " 3.99671898e-03 4.20924470e-03 3.66569475e-03 0.00000000e+00\n",
      " 3.52582807e-03 1.26639713e-03 1.27877328e-03 1.21380787e-03\n",
      " 0.00000000e+00 2.86965270e-03 9.95741373e-04 8.49723454e-04\n",
      " 7.43341224e-04 0.00000000e+00 2.00889936e-03 7.31671763e-04\n",
      " 6.69136422e-04 5.31448743e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.87600843e-03 2.05403350e-03 1.82718935e-03 1.28266453e-03\n",
      " 0.00000000e+00 2.72557173e-03 7.50593443e-04 6.31704159e-04\n",
      " 6.08977249e-04 0.00000000e+00 2.46242526e-03 6.15440101e-04\n",
      " 5.10157763e-04 5.61638238e-04 0.00000000e+00 1.06491851e-03\n",
      " 2.95954333e-04 2.73677639e-04 2.83330475e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.25896912e-02 7.97636187e-03\n",
      " 8.82402317e-03 8.49084135e-03 0.00000000e+00 8.37165286e-03\n",
      " 3.28574881e-03 3.18035056e-03 2.62789871e-03 0.00000000e+00\n",
      " 8.28764972e-03 2.87259619e-03 2.43404896e-03 1.88108083e-03\n",
      " 0.00000000e+00 6.70735777e-03 2.48274056e-03 2.08750902e-03\n",
      " 1.80772616e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.98388179e-03\n",
      " 2.99422013e-03 3.28631387e-03 2.87038010e-03 0.00000000e+00\n",
      " 3.32189515e-03 1.18802098e-03 8.70837865e-04 6.86968325e-04\n",
      " 0.00000000e+00 3.06148940e-03 1.03439514e-03 8.91447952e-04\n",
      " 7.71769755e-04 0.00000000e+00 2.26257466e-03 8.89351191e-04\n",
      " 7.26744651e-04 6.17730229e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 6.42783735e-03 2.75094708e-03 2.14339741e-03 1.82725387e-03\n",
      " 0.00000000e+00 2.75899419e-03 8.80976558e-04 7.65428813e-04\n",
      " 6.58219713e-04 0.00000000e+00 2.60968515e-03 8.92107188e-04\n",
      " 7.60844529e-04 6.39091078e-04 0.00000000e+00 1.70065611e-03\n",
      " 6.76493821e-04 6.48567655e-04 5.31484441e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.36023991e-03 1.40939713e-03 1.08365713e-03\n",
      " 7.95116455e-04 0.00000000e+00 2.54585607e-03 6.04520016e-04\n",
      " 3.94259580e-04 3.43380346e-04 0.00000000e+00 1.92663639e-03\n",
      " 4.79645913e-04 3.36925876e-04 3.27277251e-04 0.00000000e+00\n",
      " 8.49851370e-04 2.55882084e-04 2.08151836e-04 2.04867636e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.86785523e-02\n",
      " 8.56609480e-03 7.72543528e-03 5.71376149e-03 0.00000000e+00\n",
      " 6.31728250e-03 2.36742002e-03 1.95148632e-03 1.44012549e-03\n",
      " 0.00000000e+00 4.43776803e-03 1.83107637e-03 1.44491167e-03\n",
      " 1.15638693e-03 0.00000000e+00 3.04475885e-03 1.67409205e-03\n",
      " 1.48272823e-03 1.05233105e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 6.51807479e-03 2.97441727e-03 2.85364162e-03 2.42022121e-03\n",
      " 0.00000000e+00 2.56281918e-03 9.22070259e-04 7.66483486e-04\n",
      " 6.31477248e-04 0.00000000e+00 1.73053696e-03 5.73446986e-04\n",
      " 4.45410722e-04 3.38421701e-04 0.00000000e+00 8.15633142e-04\n",
      " 3.89798131e-04 3.43617393e-04 2.93022295e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 3.89510356e-03 1.67640970e-03 1.72438437e-03\n",
      " 1.53477013e-03 0.00000000e+00 1.69867549e-03 5.70048026e-04\n",
      " 4.62360816e-04 3.78098025e-04 0.00000000e+00 1.03788170e-03\n",
      " 3.69707586e-04 3.23890379e-04 2.52350293e-04 0.00000000e+00\n",
      " 7.58445042e-04 2.89973733e-04 2.30066621e-04 1.47754319e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.29143920e-03 1.07407186e-03\n",
      " 1.02444118e-03 8.68809647e-04 0.00000000e+00 1.06966063e-03\n",
      " 4.87273378e-04 4.18197539e-04 3.17058960e-04 0.00000000e+00\n",
      " 1.03122968e-03 3.97095355e-04 3.13174912e-04 2.92418351e-04\n",
      " 0.00000000e+00 7.99413739e-04 3.69555984e-04 3.86514186e-04\n",
      " 3.34616518e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92741f51f0d94ba49426ec45716a1adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04011307001085133\n"
     ]
    }
   ],
   "source": [
    "times = 20\n",
    "for k,(g, labels) in (enumerate(data)):\n",
    "    \n",
    "    for j in tqdm(range(times)):\n",
    "        A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "        \n",
    "\n",
    "        for i in range(g.num_edges()):\n",
    "            A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "#         A = graph_stochastic_sampling(A,p=0.9)\n",
    "        GSTmodel = stochastic_DiffusionScattering(args.numScales, args.numLayers, A)\n",
    "        node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "        \n",
    "        co_GST = GSTmodel.computeTransform(node_attr)\n",
    "\n",
    "        if j == 0:\n",
    "            num_coe = np.shape(co_GST)[2]\n",
    "            GSTcoe_all = np.zeros((times,num_coe))\n",
    "\n",
    "        GSTcoe_all[j]=co_GST[0,0,:]\n",
    "    print(GSTcoe_all[1])\n",
    "    coe_mean = np.mean(GSTcoe_all,0)\n",
    "#     print(coe_mean.shape)\n",
    "#     print(coe_mean)\n",
    "    if k == 0:\n",
    "        break\n",
    "\n",
    "times = 20\n",
    "for k,(g, labels) in (enumerate(data)):\n",
    "    \n",
    "    for j in tqdm(range(times)):\n",
    "        A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "        \n",
    "\n",
    "        for i in range(g.num_edges()):\n",
    "            A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "#         A = graph_stochastic_sampling(A,p=0.9)\n",
    "        GSTmodel = stochastic_DiffusionScattering(args.numScales, args.numLayers, A)\n",
    "        node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "        \n",
    "        co_GST = GSTmodel.computeTransform(node_attr)\n",
    "\n",
    "        if j == 0:\n",
    "#             num_coe = np.shape(co_GST)[2]\n",
    "            bias_all = np.zeros(times)\n",
    "#         print(co_GST[0,0,:])\n",
    "        coe_bias = co_GST[0,0,:]-coe_mean\n",
    "        coe_bias_norm = pow(np.linalg.norm(coe_bias),2)\n",
    "        bias_all[j] = coe_bias_norm\n",
    "        var_coe = np.mean(bias_all)\n",
    "    print(var_coe)\n",
    "\n",
    "#         GSTcoe_all[j]=co_GST[0,0,:]-coe_mean\n",
    "\n",
    "#     coe_mean = np.mean(GSTcoe_all,0)\n",
    "#     print(coe_mean.shape)\n",
    "    if k == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
