{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import argparse\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from progress.bar import Bar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve,auc,accuracy_score\n",
    "import pickle\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import SGD\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "# import dgl.data.TUDataset as TUDataset\n",
    "# our package\n",
    "from Modules.STGST_torch_s2 import STGSTModule\n",
    "import Modules.graphScattering as np_GST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GST_coef_dataset(Dataset):\n",
    "    def __init__(self, GSTcoe_all, label_all, split='train', test_rate=0.2):\n",
    "\n",
    "        self.lenth = len(label_all)\n",
    "\n",
    "        # if self.normalize:\n",
    "        #     phis_mean = np.mean(phis[train_idx],axis=0)\n",
    "        #     phis_std = np.std(phis[train_idx], axis=0)\n",
    "        #     phis = (phis - phis_mean) / phis_std\n",
    "        #     phis[np.isnan(phis)] = 0 # phis_std may be zero, remove invalid values here\n",
    "        #     phis[np.isinf(phis)] = 0\n",
    "\n",
    "        train_idx = int(self.lenth*(1-test_rate))\n",
    "\n",
    "        if split == 'train':\n",
    "            self.GSTcoe = GSTcoe_all[0:train_idx]\n",
    "            self.labels = label_all[0:train_idx]\n",
    "        elif split == 'test':\n",
    "            self.GSTcoe = GSTcoe_all[(train_idx):]\n",
    "            self.labels = label_all[(train_idx):]\n",
    "        else:\n",
    "            raise RuntimeError('Invalid split')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.GSTcoe[index,:,:], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class MLPs(nn.Module):\n",
    "    def __init__(self, class_num=2, midnum = 128, nodeNum=None):\n",
    "        super(MLPs, self).__init__()\n",
    "        self.nodeNum = nodeNum\n",
    "        self.mlp1 = nn.Linear(in_features=self.nodeNum*63, out_features=midnum, bias=True)\n",
    "        # self.dropout1 = nn.Dropout(0.5)\n",
    "        self.mlp2 = nn.Linear(in_features=midnum, out_features=class_num, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.mlp2(x)\n",
    "        return x\n",
    "\n",
    "def computeNcoe(scale,layers):\n",
    "    num = 0\n",
    "    for i in range(layers):\n",
    "        num = num + pow(scale, i)\n",
    "    return num\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.layer = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "def sign(x):\n",
    "    x[x>=0] = 1\n",
    "    x[x<0] = -1\n",
    "    return x\n",
    "\n",
    "def loss_func(scores, label, type=\"svm\"):\n",
    "    assert type==\"perceptron\" or type==\"svm\", \"loss type error\"\n",
    "    if type == \"perceptron\":\n",
    "        # 感知机损失函数，label取值集合为{-1, 1}\n",
    "        loss = -label*scores\n",
    "    else:\n",
    "        # SVM损失函数，label取值集合为{-1, 1}\n",
    "        loss = 1-label*scores\n",
    "   \n",
    "    loss[loss<=0] = 0\n",
    "    return torch.sum(loss)\n",
    "\n",
    "def pred(x):\n",
    "    return sign(x)\n",
    "\n",
    "def valid(test_loader,model):\n",
    "    pred_scores=[]\n",
    "    labels=[]\n",
    "    for j, (input, target) in enumerate(test_loader):\n",
    "        input_var = input.to(device).float()\n",
    "        target_var =target.to(device).int()\n",
    "        scores = model(input_var).squeeze(1).squeeze(1)\n",
    "        for m in range(len(target)):\n",
    "            pred_scores.append(scores[m].item())\n",
    "            labels.append(np.float(target[m].numpy()))\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    # print(labels)\n",
    "    labels[labels>0]=1\n",
    "    labels[labels<=0]=0    \n",
    "    # print(labels)\n",
    "    pred_scores=np.array(pred_scores)\n",
    "    # print(pred_scores)\n",
    "    pred_scores[pred_scores>0]=1\n",
    "    pred_scores[pred_scores<=0]=0\n",
    "    # print(pred_scores)\n",
    "    acc= accuracy_score(labels, pred_scores)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "parser = argparse.ArgumentParser(description=\"GST configuration\")\n",
    "parser.add_argument(\"--datadir\", type=str, default='/DATA7_DB7/data/gjliu/dataset', help=\"path of dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='DD', help=\"name of dataset\")\n",
    "parser.add_argument(\"--split\", type=str, default='train')\n",
    "parser.add_argument(\"--epochs\", type=int, default= 10000)\n",
    "parser.add_argument(\"--batchsize\", type=int, default= 1, help=\"batch size of dataset\")\n",
    "parser.add_argument('--workers',default=1,type=int, metavar='N')\n",
    "parser.add_argument(\"--numScales\", type=int, default= 5, help=\"size of filter bank\")\n",
    "parser.add_argument(\"--numLayers\", type=int, default= 5, help=\"layers of GST\")\n",
    "args = parser.parse_known_args()[0]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "num_gst_coe = computeNcoe(args.numScales, args.numLayers)\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = dgl.data.TUDataset('ENZYMES')\n",
    "# data = dgl.data.GINDataset('DD', self_loop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 6\n",
      "Number of num_nodes: 37\n",
      "Number of num_edges: 168\n",
      "label: tensor(5)\n",
      "node_attr torch.Size([37, 18])\n"
     ]
    }
   ],
   "source": [
    "g, label = data[0]\n",
    "print('Number of categories:', data.num_labels)\n",
    "print('Number of num_nodes:', g.num_nodes())\n",
    "print('Number of num_edges:', g.num_edges())\n",
    "print('label:', label)\n",
    "print('node_attr', g.ndata['node_attr'].shape)\n",
    "# print('edata:', g.edata)\n",
    "# print('edges:',g.edges())\n",
    "# print('edges:',g.edges()[0][0:200])\n",
    "# print('edges:',g.edges()[1][0:200])\n",
    "# print('length',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 18, 37)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(np.expand_dims(g.ndata['node_attr'].permute(1,0).numpy(), axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 42)\n"
     ]
    }
   ],
   "source": [
    "node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "print(np.shape(node_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703a96f5bc5f4bf78ea903cc9c97dc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataloader = GraphDataLoader(data, batch_size=1, shuffle=True)\n",
    "label_all = np.zeros(len(data))\n",
    "# bar = Bar('>>>', fill='>', max=len(dataloader))\n",
    "for k,(g, labels) in tqdm(enumerate(data)):\n",
    "    \n",
    "    A = np.zeros((g.num_nodes(),g.num_nodes()))\n",
    "    for i in range(g.num_edges()):\n",
    "        A[g.edges()[0][i].item()][g.edges()[1][i].item()] = 1\n",
    "\n",
    "    GSTmodel = np_GST.DiffusionScattering(args.numScales, args.numLayers, A)        \n",
    "#     node_attr = np.expand_dims(np.expand_dims(g.ndata['node_attr'].numpy(), axis=0), axis=0)\n",
    "    \n",
    "    fake_node_attr = np.ones(g.num_nodes())\n",
    "    node_attr = np.expand_dims(np.expand_dims(fake_node_attr, axis=0), axis=0)\n",
    "#     print(np.shape(node_attr))\n",
    "    co_GST = GSTmodel.computeTransform(node_attr)\n",
    "    if k == 0:\n",
    "        num_coe = np.shape(co_GST)[2]\n",
    "        GSTcoe_all = np.zeros((len(data),1,num_coe))\n",
    "\n",
    "    GSTcoe_all[k] = co_GST[0]\n",
    "    label_all[k] = int(labels.item())\n",
    "#     bar.next()\n",
    "# bar.finish()\n",
    "np.save('/DATA7_DB7/data/gjliu/dataset/COLLAB/allphi_COLLAB.npy',GSTcoe_all)\n",
    "np.save('/DATA7_DB7/data/gjliu/dataset/COLLAB/alllabel_COLLAB.npy',label_all)\n",
    "print(label_all)\n",
    "label_all = label_all*2-1\n",
    "print(label_all)\n",
    "print(num_coe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "g, labels = data[0]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1113,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(label_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "print(len(label_all[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(GSTcoe_all[0]) (1, 781)\n",
      "[[8.22222222e+00 2.27079080e+00 7.93636873e-01 7.64380080e-01\n",
      "  6.67090487e-01 3.84449919e-01 7.16750186e-01 2.77906196e-01\n",
      "  2.67350304e-01 2.45602695e-01 2.03523167e-01 2.79047787e-01\n",
      "  7.71773504e-02 6.95870825e-02 6.46447170e-02 5.55899136e-02\n",
      "  3.10825909e-01 9.06355558e-02 5.92137860e-02 5.09254776e-02\n",
      "  4.73949939e-02 2.38204682e-01 7.00564701e-02 4.28111443e-02\n",
      "  2.84209054e-02 1.84420264e-02 8.82163381e-02 4.02961963e-02\n",
      "  3.51149572e-02 2.45288696e-02 1.95637844e-02 2.87021262e-01\n",
      "  8.24744612e-02 7.31945365e-02 4.98342149e-02 3.24342970e-02\n",
      "  1.36340936e-01 2.97025268e-02 2.73919194e-02 2.20415321e-02\n",
      "  1.53706712e-02 8.93182020e-02 2.59239396e-02 2.27581883e-02\n",
      "  1.84113636e-02 1.46757966e-02 5.54591849e-02 2.40960491e-02\n",
      "  1.93493495e-02 1.30199606e-02 8.55968007e-03 3.40753147e-02\n",
      "  1.83193474e-02 1.79125772e-02 1.43881176e-02 1.18634534e-02\n",
      "  7.14946936e-02 3.45051481e-02 3.71366545e-02 3.40774451e-02\n",
      "  2.65244057e-02 3.91907177e-02 1.01631521e-02 8.84639090e-03\n",
      "  7.47928655e-03 4.75741451e-03 2.62915436e-02 7.43066040e-03\n",
      "  6.12455381e-03 4.34077813e-03 3.40841142e-03 1.28222074e-02\n",
      "  5.83598969e-03 4.67448605e-03 2.68477883e-03 2.10239035e-03\n",
      "  7.22371421e-03 3.76595295e-03 4.10835423e-03 3.64497708e-03\n",
      "  3.58759323e-03 8.88760080e-02 2.85231058e-02 2.80282737e-02\n",
      "  2.67768028e-02 2.64951670e-02 2.65688364e-02 8.47423557e-03\n",
      "  8.14499585e-03 6.76849800e-03 3.94755221e-03 1.96582868e-02\n",
      "  7.16487123e-03 6.67965103e-03 5.94293220e-03 4.66134748e-03\n",
      "  1.34991364e-02 5.87119348e-03 4.51332914e-03 3.17461838e-03\n",
      "  2.94211208e-03 5.89680237e-03 2.99255918e-03 2.70930346e-03\n",
      "  1.72079718e-03 1.97908490e-03 5.69317616e-02 1.86575510e-02\n",
      "  1.73629140e-02 1.33599167e-02 9.95618441e-03 2.17636949e-02\n",
      "  7.10164197e-03 6.60534331e-03 5.41433671e-03 3.28291729e-03\n",
      "  1.60621442e-02 5.27340633e-03 4.95087474e-03 4.60830353e-03\n",
      "  3.04690489e-03 9.05028815e-03 3.44779341e-03 3.29322048e-03\n",
      "  3.03688730e-03 2.14700116e-03 2.85879463e-03 1.89791415e-03\n",
      "  2.50492853e-03 2.67243558e-03 1.80978210e-03 2.68442953e-02\n",
      "  4.93366101e-03 3.54414567e-03 3.87693888e-03 4.61554257e-03\n",
      "  1.25676025e-02 2.64610963e-03 1.75264770e-03 1.31159541e-03\n",
      "  1.07011316e-03 1.08118627e-02 3.17870171e-03 2.17113303e-03\n",
      "  1.75225454e-03 1.45774515e-03 6.78160856e-03 2.79813556e-03\n",
      "  2.24027704e-03 1.89321695e-03 1.66866604e-03 2.76834399e-03\n",
      "  1.40674098e-03 1.42593890e-03 1.42950077e-03 1.35205801e-03\n",
      "  6.71826795e-02 2.93587571e-02 2.96822147e-02 2.26403119e-02\n",
      "  1.91734126e-02 2.96487525e-02 8.71907032e-03 6.93935930e-03\n",
      "  6.51043256e-03 6.40543872e-03 2.36564314e-02 7.48583851e-03\n",
      "  5.85482178e-03 4.77950868e-03 4.13763060e-03 1.31439150e-02\n",
      "  5.59443350e-03 5.14929677e-03 3.96158690e-03 3.62942414e-03\n",
      "  7.76721241e-03 3.63205191e-03 3.81656442e-03 3.55717956e-03\n",
      "  2.68566720e-03 2.59724657e-02 1.17400922e-02 1.23009643e-02\n",
      "  1.03517183e-02 7.06404134e-03 1.07145831e-02 3.83391116e-03\n",
      "  2.61012415e-03 2.19225937e-03 2.17693847e-03 7.89457703e-03\n",
      "  3.22772570e-03 2.62409063e-03 2.28894861e-03 2.18310062e-03\n",
      "  6.90145266e-03 2.88770984e-03 2.60718978e-03 2.35309277e-03\n",
      "  2.07577600e-03 3.77947966e-03 1.69906688e-03 1.60958094e-03\n",
      "  1.44919508e-03 1.09774921e-03 2.72305399e-02 9.69927736e-03\n",
      "  1.00171998e-02 9.95430284e-03 7.96613737e-03 7.93635286e-03\n",
      "  3.53878797e-03 3.41596160e-03 2.98706009e-03 2.29242727e-03\n",
      "  7.26729773e-03 3.05616967e-03 2.81970191e-03 2.19128435e-03\n",
      "  1.82350382e-03 5.85472583e-03 2.46291443e-03 2.08427662e-03\n",
      "  1.69801256e-03 1.43089726e-03 2.91676103e-03 1.23552749e-03\n",
      "  1.05226578e-03 8.94371509e-04 6.67769886e-04 1.50216474e-02\n",
      "  4.54438203e-03 4.04460762e-03 3.81320566e-03 3.51923193e-03\n",
      "  8.31705685e-03 1.98378375e-03 1.88543503e-03 1.79498245e-03\n",
      "  1.28540118e-03 7.07583030e-03 2.02870049e-03 2.06307874e-03\n",
      "  2.03422386e-03 1.64558229e-03 4.15982213e-03 1.37124326e-03\n",
      "  1.36226339e-03 1.31521013e-03 9.99910824e-04 1.24087733e-03\n",
      "  7.81593719e-04 9.69071580e-04 9.36813925e-04 5.81440386e-04\n",
      "  1.07045149e-02 2.90335316e-03 2.36684100e-03 1.77917128e-03\n",
      "  1.40533121e-03 6.49725184e-03 1.39602874e-03 8.45985672e-04\n",
      "  8.95389759e-04 1.02930815e-03 6.47695740e-03 1.54446430e-03\n",
      "  1.09134551e-03 1.19440029e-03 1.45293052e-03 3.45591690e-03\n",
      "  1.30025507e-03 1.30755831e-03 1.33104784e-03 1.35896046e-03\n",
      "  1.89964821e-03 1.15836590e-03 1.50071640e-03 1.49405565e-03\n",
      "  1.20709182e-03 2.62372949e-02 8.80748843e-03 7.91702821e-03\n",
      "  6.63446970e-03 4.36974419e-03 8.95421940e-03 3.16236537e-03\n",
      "  3.07139176e-03 2.81066549e-03 2.46425578e-03 7.84866734e-03\n",
      "  3.26130451e-03 2.76999199e-03 2.26049246e-03 2.47118769e-03\n",
      "  6.78953598e-03 3.02814494e-03 2.37713730e-03 1.39823018e-03\n",
      "  1.59392480e-03 3.96892929e-03 1.98272632e-03 1.87623617e-03\n",
      "  1.46929337e-03 1.42679617e-03 7.81755577e-03 3.56080009e-03\n",
      "  3.97937022e-03 4.18425674e-03 3.18833941e-03 4.30424120e-03\n",
      "  1.28154193e-03 8.11749561e-04 6.76922245e-04 6.17331462e-04\n",
      "  4.11537147e-03 1.27919647e-03 8.33694377e-04 5.63874568e-04\n",
      "  3.65559915e-04 2.71487606e-03 8.78752173e-04 5.97106557e-04\n",
      "  4.50797591e-04 4.01923904e-04 1.18753170e-03 5.43109831e-04\n",
      "  4.84510149e-04 3.52295762e-04 2.79985959e-04 5.74746434e-03\n",
      "  2.77576092e-03 2.98693837e-03 2.72839498e-03 2.12843934e-03\n",
      "  3.29736564e-03 8.91349074e-04 6.32660400e-04 6.20741892e-04\n",
      "  6.91567199e-04 2.34723083e-03 7.00438412e-04 5.23175760e-04\n",
      "  4.00899789e-04 2.58844753e-04 1.51612997e-03 5.46534941e-04\n",
      "  4.88435577e-04 4.07296083e-04 2.36529556e-04 5.22604832e-04\n",
      "  2.89337243e-04 3.30801167e-04 2.95077965e-04 2.28346666e-04\n",
      "  4.99090284e-03 1.33113358e-03 1.10482842e-03 7.23579109e-04\n",
      "  4.74998485e-04 2.27262001e-03 5.44470966e-04 3.62434854e-04\n",
      "  2.83902360e-04 2.67135302e-04 1.93235873e-03 5.10555129e-04\n",
      "  3.88044588e-04 3.30829992e-04 3.77034350e-04 8.93923412e-04\n",
      "  2.66366518e-04 2.56412150e-04 2.44308074e-04 2.12875130e-04\n",
      "  2.21217829e-04 1.52002463e-04 2.10180803e-04 2.31145544e-04\n",
      "  1.90897907e-04 3.06445395e-03 8.50190206e-04 6.65066088e-04\n",
      "  4.77233195e-04 5.73333915e-04 1.76409549e-03 3.95638848e-04\n",
      "  2.44022014e-04 2.45261540e-04 3.28006475e-04 1.47376043e-03\n",
      "  4.01182260e-04 3.34983265e-04 3.24023024e-04 3.81364838e-04\n",
      "  7.63170991e-04 3.91149458e-04 4.32428197e-04 4.23378722e-04\n",
      "  4.00882481e-04 5.00855418e-04 3.07846352e-04 4.08395615e-04\n",
      "  4.65351158e-04 4.22179307e-04 1.90737178e-02 6.09905284e-03\n",
      "  6.60435047e-03 6.08511373e-03 4.98434947e-03 8.50677593e-03\n",
      "  3.29449146e-03 2.50694985e-03 1.72153818e-03 1.72204242e-03\n",
      "  7.83487822e-03 2.60329969e-03 2.15468810e-03 1.34506494e-03\n",
      "  8.61865659e-04 5.13160199e-03 1.60933171e-03 1.35594952e-03\n",
      "  1.13871250e-03 1.30540491e-03 2.66541518e-03 1.20953119e-03\n",
      "  1.18404889e-03 1.51779121e-03 2.36520129e-03 6.02239323e-03\n",
      "  2.67790396e-03 2.54030370e-03 2.46202137e-03 2.32276142e-03\n",
      "  2.63721297e-03 9.11314237e-04 6.54023947e-04 5.13914952e-04\n",
      "  5.62251295e-04 2.48687851e-03 8.45005519e-04 5.93927698e-04\n",
      "  5.04929432e-04 5.48833872e-04 2.02129608e-03 7.19179336e-04\n",
      "  5.95794598e-04 5.14656796e-04 4.89358243e-04 7.03539708e-04\n",
      "  3.92777444e-04 4.68644092e-04 4.47617731e-04 2.86478449e-04\n",
      "  6.03435044e-03 2.44686705e-03 1.87786537e-03 1.17166777e-03\n",
      "  9.30677907e-04 2.47971887e-03 7.91840125e-04 6.23245286e-04\n",
      "  4.69508100e-04 3.48145508e-04 2.38642897e-03 8.48538090e-04\n",
      "  6.82508519e-04 4.88719190e-04 3.71460449e-04 1.39826169e-03\n",
      "  6.88079048e-04 6.70369756e-04 5.29428907e-04 4.31423391e-04\n",
      "  7.48973755e-04 4.83204639e-04 6.04922043e-04 5.67873008e-04\n",
      "  3.34049554e-04 4.92360205e-03 1.03053850e-03 8.47304275e-04\n",
      "  8.23450202e-04 9.55929275e-04 2.07056074e-03 5.10280187e-04\n",
      "  4.41851701e-04 4.31299907e-04 3.22432244e-04 1.51051012e-03\n",
      "  4.78276180e-04 4.81768352e-04 4.93781472e-04 3.75407097e-04\n",
      "  8.19610939e-04 2.98524841e-04 3.41673180e-04 3.43478376e-04\n",
      "  2.80683065e-04 3.72698109e-04 1.95457348e-04 2.46299572e-04\n",
      "  2.69386321e-04 2.95916312e-04 2.17632691e-03 6.26791936e-04\n",
      "  5.33691883e-04 3.85471135e-04 2.90671273e-04 1.26432719e-03\n",
      "  2.70202336e-04 1.89697653e-04 1.76037774e-04 1.21408950e-04\n",
      "  1.11763454e-03 2.60455518e-04 2.34461869e-04 1.99700156e-04\n",
      "  1.36468119e-04 4.40635468e-04 2.40040246e-04 2.52384802e-04\n",
      "  2.17380129e-04 2.09628866e-04 2.11127571e-04 1.35542212e-04\n",
      "  1.84845490e-04 2.34682850e-04 2.75826714e-04 1.79386735e-02\n",
      "  5.96639311e-03 3.60885382e-03 2.98641224e-03 3.87916184e-03\n",
      "  5.38200731e-03 1.49942488e-03 1.10764811e-03 1.08046417e-03\n",
      "  1.34860862e-03 4.29246741e-03 1.29206032e-03 9.92289077e-04\n",
      "  9.06687347e-04 1.17703223e-03 4.53993764e-03 1.64222066e-03\n",
      "  1.40101943e-03 1.00020450e-03 7.24802727e-04 2.02047721e-03\n",
      "  7.86179464e-04 8.24345287e-04 7.91602298e-04 6.81210659e-04\n",
      "  7.61573672e-03 2.31503018e-03 1.95434900e-03 1.92354239e-03\n",
      "  1.88615584e-03 2.31363366e-03 5.40297098e-04 4.34205535e-04\n",
      "  4.00201287e-04 3.86578708e-04 1.94912395e-03 6.20084171e-04\n",
      "  5.01770864e-04 4.28833932e-04 3.65085036e-04 1.47071003e-03\n",
      "  5.43209044e-04 5.31129017e-04 5.21028952e-04 4.25089333e-04\n",
      "  6.19200597e-04 3.75532600e-04 4.94709324e-04 5.21953977e-04\n",
      "  3.58857632e-04 3.27921443e-03 1.42315568e-03 1.53632827e-03\n",
      "  1.53057715e-03 9.55704241e-04 1.65104641e-03 6.20077041e-04\n",
      "  5.75431865e-04 5.27552604e-04 3.52996386e-04 1.85690886e-03\n",
      "  7.02156018e-04 5.20946126e-04 4.72291678e-04 3.92304805e-04\n",
      "  1.45851422e-03 5.39691757e-04 4.82607458e-04 4.70645968e-04\n",
      "  4.19139198e-04 7.29390135e-04 3.38596573e-04 3.91120872e-04\n",
      "  3.82940634e-04 3.03187210e-04 3.02085248e-03 1.02117402e-03\n",
      "  9.47096349e-04 8.55589086e-04 5.44357498e-04 1.20505620e-03\n",
      "  4.46322251e-04 4.74188504e-04 4.62726193e-04 3.09966512e-04\n",
      "  8.57355813e-04 3.96534384e-04 4.12374936e-04 3.96806197e-04\n",
      "  2.98449041e-04 7.88535921e-04 3.45204430e-04 3.74614074e-04\n",
      "  3.62587889e-04 2.62242634e-04 4.23630564e-04 2.47901842e-04\n",
      "  3.08226186e-04 3.27840653e-04 2.17621847e-04 8.16785257e-04\n",
      "  3.34344855e-04 3.67957281e-04 3.54025869e-04 2.46232734e-04\n",
      "  5.26773129e-04 2.11454294e-04 2.15098539e-04 2.23038834e-04\n",
      "  1.68016425e-04 7.70755096e-04 2.87033321e-04 2.77554080e-04\n",
      "  2.89564136e-04 2.23186600e-04 6.06897507e-04 2.64841739e-04\n",
      "  2.68540305e-04 2.84832182e-04 2.38196892e-04 3.11797658e-04\n",
      "  1.71521955e-04 1.95837238e-04 1.87471578e-04 1.15789777e-04\n",
      "  6.61769736e-03 2.78647965e-03 2.57817671e-03 2.18287947e-03\n",
      "  1.72589645e-03 2.28524794e-03 6.97909473e-04 4.64439950e-04\n",
      "  2.74157527e-04 2.13623283e-04 1.09521502e-03 3.97013151e-04\n",
      "  2.66496981e-04 1.50033314e-04 1.34964664e-04 6.19264047e-04\n",
      "  2.99091518e-04 2.75848496e-04 2.08020684e-04 1.67828302e-04\n",
      "  4.79379045e-04 2.59908395e-04 2.79620984e-04 2.74624903e-04\n",
      "  3.10988331e-04 2.15400328e-03 1.05863284e-03 1.08848634e-03\n",
      "  8.96319089e-04 5.49458489e-04 7.45462675e-04 2.33870679e-04\n",
      "  1.57863282e-04 1.24388302e-04 1.18618369e-04 6.47632517e-04\n",
      "  2.57227093e-04 1.99136940e-04 1.27552350e-04 9.45539278e-05\n",
      "  3.94120629e-04 1.84187729e-04 1.84653174e-04 1.42237212e-04\n",
      "  9.73902216e-05 1.64622839e-04 1.00920138e-04 1.27244117e-04\n",
      "  1.33273662e-04 1.24123207e-04 2.42272050e-03 1.12321605e-03\n",
      "  9.46732727e-04 6.93031746e-04 5.40822343e-04 7.79999450e-04\n",
      "  2.68740096e-04 2.28190371e-04 1.66265267e-04 1.24076836e-04\n",
      "  6.45336723e-04 2.71509981e-04 2.26375300e-04 1.61724701e-04\n",
      "  9.90813005e-05 4.06066999e-04 1.84634013e-04 1.64980030e-04\n",
      "  1.17539584e-04 6.35817375e-05 2.30458845e-04 1.27555956e-04\n",
      "  1.39894818e-04 1.22804456e-04 1.03197948e-04 1.70983189e-03\n",
      "  6.74748666e-04 5.63491835e-04 4.20836953e-04 3.40616927e-04\n",
      "  5.75927152e-04 2.25800352e-04 2.01007627e-04 1.60921155e-04\n",
      "  1.21386915e-04 6.05053760e-04 2.31512596e-04 1.88005694e-04\n",
      "  1.13984938e-04 6.52865508e-05 3.29901143e-04 1.30041233e-04\n",
      "  1.10661810e-04 9.15720593e-05 7.34074357e-05 2.27912267e-04\n",
      "  1.24960379e-04 1.38452588e-04 1.25238747e-04 1.07208372e-04\n",
      "  6.86912079e-04 3.08105960e-04 2.97608712e-04 2.67959997e-04\n",
      "  2.18157183e-04 4.01544355e-04 1.53773395e-04 1.25847361e-04\n",
      "  9.75006779e-05 7.78887359e-05 4.36177601e-04 1.80427891e-04\n",
      "  1.47750812e-04 1.04459708e-04 6.33759820e-05 3.04257115e-04\n",
      "  1.57430566e-04 1.65561704e-04 1.32616609e-04 7.73197008e-05\n",
      "  2.11409109e-04 1.17178428e-04 1.31396100e-04 1.15615987e-04\n",
      "  8.05827433e-05]]\n"
     ]
    }
   ],
   "source": [
    "print('np.shape(GSTcoe_all[0])',np.shape(GSTcoe_all[0]))\n",
    "print(GSTcoe_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9999\n",
      "----------\n",
      "np.shape(scores) torch.Size([4]) tensor([0.3225, 0.2459, 0.2877, 0.3435], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "np.shape(target_var) torch.Size([4]) tensor([-1, -1, -1, -1], device='cuda:0', dtype=torch.int32)\n",
      "loss= 5.19954776763916 acc= 0.0\n",
      "epoch time: 0.03913617134094238   total time: 0.03944993019104004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GSTdataset_train = GST_coef_dataset(GSTcoe_all, label_all, 'train')\n",
    "GSTdataset_test = GST_coef_dataset(GSTcoe_all, label_all, 'test')\n",
    "train_loader = torch.utils.data.DataLoader(GSTdataset_train, batch_size=4,\n",
    "               shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(GSTdataset_test, batch_size=4,\n",
    "               shuffle=False, pin_memory=True)\n",
    "model = Perceptron(input_dim = num_coe)\n",
    "model = nn.DataParallel(model, device_ids = [i for i in range(torch.cuda.device_count())])\n",
    "model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(100), gamma=0.3)\n",
    "\n",
    "st = time.time()\n",
    "#------------------------------------- 训练阶段-----------------------------------------------\n",
    "for epoch in range(1):\n",
    "    st_epoch = time.time()\n",
    "    print('Epoch {}/{}'.format(epoch, args.epochs - 1))\n",
    "    print('-' * 10)\n",
    "    bar = Bar('>>>', fill='>', max=len(train_loader))\n",
    "    loss_train = []\n",
    "    for i, (input, target) in (enumerate(train_loader)):\n",
    "\n",
    "\n",
    "        input_var = input.to(device).float()\n",
    "        target_var =target.to(device).int()\n",
    "        # print(np.shape(input_var))\n",
    "        # print(np.shape(target_var))\n",
    "\n",
    "        # 前向传播\n",
    "        scores = model(input_var).squeeze(1).squeeze(1)\n",
    "        print('np.shape(scores)',np.shape(scores),scores)\n",
    "        print('np.shape(target_var)',np.shape(target_var),target_var)\n",
    "        loss = loss_func(scores, target_var, \"svm\")\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train.append(loss.item())\n",
    "            # for name,param in model.named_parameters():\n",
    "            #     print(name, param)\n",
    "        bar.next()\n",
    "        break\n",
    "    bar.finish()\n",
    "    scheduler.step()\n",
    "    if epoch % 1 == 0:\n",
    "\n",
    "        # 计算分类的准确率\n",
    "        acc = valid(test_loader,model)\n",
    "#         acc = valid(train_loader,model)\n",
    "        print(\"loss=\", np.mean(loss_train),\"acc=\", acc) #loss.detach().cpu().numpy()\n",
    "\n",
    "        # print('zantin')\n",
    "        # input()        \n",
    "\n",
    "    bt_epoch = time.time()\n",
    "    print('epoch time:',bt_epoch-st_epoch,'  total time:', bt_epoch - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "acc= accuracy_score([2,3,0,0], [1,3,0,2])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
